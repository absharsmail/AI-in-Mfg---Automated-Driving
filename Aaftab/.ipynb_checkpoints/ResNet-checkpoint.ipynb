{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "from random import shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import tensorflow as tf\n",
    "config = tf.compat.v1.ConfigProto(gpu_options = \n",
    "                         tf.compat.v1.GPUOptions(per_process_gpu_memory_fraction=0.8)\n",
    "# device_count = {'GPU': 1}\n",
    ")\n",
    "config.gpu_options.allow_growth = True\n",
    "session = tf.compat.v1.Session(config=config)\n",
    "tf.compat.v1.keras.backend.set_session(session)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 150, 300, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1_pad (ZeroPadding2D)       (None, 156, 306, 3)  0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1_conv (Conv2D)             (None, 75, 150, 64)  9472        conv1_pad[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1_bn (BatchNormalization)   (None, 75, 150, 64)  256         conv1_conv[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1_relu (Activation)         (None, 75, 150, 64)  0           conv1_bn[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "pool1_pad (ZeroPadding2D)       (None, 77, 152, 64)  0           conv1_relu[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "pool1_pool (MaxPooling2D)       (None, 38, 75, 64)   0           pool1_pad[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_conv (Conv2D)    (None, 38, 75, 64)   4160        pool1_pool[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_bn (BatchNormali (None, 38, 75, 64)   256         conv2_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_relu (Activation (None, 38, 75, 64)   0           conv2_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_conv (Conv2D)    (None, 38, 75, 64)   36928       conv2_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_bn (BatchNormali (None, 38, 75, 64)   256         conv2_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_relu (Activation (None, 38, 75, 64)   0           conv2_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_0_conv (Conv2D)    (None, 38, 75, 256)  16640       pool1_pool[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_3_conv (Conv2D)    (None, 38, 75, 256)  16640       conv2_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_0_bn (BatchNormali (None, 38, 75, 256)  1024        conv2_block1_0_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_3_bn (BatchNormali (None, 38, 75, 256)  1024        conv2_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_add (Add)          (None, 38, 75, 256)  0           conv2_block1_0_bn[0][0]          \n",
      "                                                                 conv2_block1_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_out (Activation)   (None, 38, 75, 256)  0           conv2_block1_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_conv (Conv2D)    (None, 38, 75, 64)   16448       conv2_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_bn (BatchNormali (None, 38, 75, 64)   256         conv2_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_relu (Activation (None, 38, 75, 64)   0           conv2_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_2_conv (Conv2D)    (None, 38, 75, 64)   36928       conv2_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_2_bn (BatchNormali (None, 38, 75, 64)   256         conv2_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_2_relu (Activation (None, 38, 75, 64)   0           conv2_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_3_conv (Conv2D)    (None, 38, 75, 256)  16640       conv2_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_3_bn (BatchNormali (None, 38, 75, 256)  1024        conv2_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_add (Add)          (None, 38, 75, 256)  0           conv2_block1_out[0][0]           \n",
      "                                                                 conv2_block2_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_out (Activation)   (None, 38, 75, 256)  0           conv2_block2_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_conv (Conv2D)    (None, 38, 75, 64)   16448       conv2_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_bn (BatchNormali (None, 38, 75, 64)   256         conv2_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_relu (Activation (None, 38, 75, 64)   0           conv2_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_2_conv (Conv2D)    (None, 38, 75, 64)   36928       conv2_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_2_bn (BatchNormali (None, 38, 75, 64)   256         conv2_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_2_relu (Activation (None, 38, 75, 64)   0           conv2_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_3_conv (Conv2D)    (None, 38, 75, 256)  16640       conv2_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_3_bn (BatchNormali (None, 38, 75, 256)  1024        conv2_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_add (Add)          (None, 38, 75, 256)  0           conv2_block2_out[0][0]           \n",
      "                                                                 conv2_block3_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_out (Activation)   (None, 38, 75, 256)  0           conv2_block3_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_conv (Conv2D)    (None, 19, 38, 128)  32896       conv2_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_bn (BatchNormali (None, 19, 38, 128)  512         conv3_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_relu (Activation (None, 19, 38, 128)  0           conv3_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_2_conv (Conv2D)    (None, 19, 38, 128)  147584      conv3_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_2_bn (BatchNormali (None, 19, 38, 128)  512         conv3_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_2_relu (Activation (None, 19, 38, 128)  0           conv3_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_0_conv (Conv2D)    (None, 19, 38, 512)  131584      conv2_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_3_conv (Conv2D)    (None, 19, 38, 512)  66048       conv3_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_0_bn (BatchNormali (None, 19, 38, 512)  2048        conv3_block1_0_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_3_bn (BatchNormali (None, 19, 38, 512)  2048        conv3_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_add (Add)          (None, 19, 38, 512)  0           conv3_block1_0_bn[0][0]          \n",
      "                                                                 conv3_block1_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_out (Activation)   (None, 19, 38, 512)  0           conv3_block1_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_conv (Conv2D)    (None, 19, 38, 128)  65664       conv3_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_bn (BatchNormali (None, 19, 38, 128)  512         conv3_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_relu (Activation (None, 19, 38, 128)  0           conv3_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_2_conv (Conv2D)    (None, 19, 38, 128)  147584      conv3_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_2_bn (BatchNormali (None, 19, 38, 128)  512         conv3_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_2_relu (Activation (None, 19, 38, 128)  0           conv3_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_3_conv (Conv2D)    (None, 19, 38, 512)  66048       conv3_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_3_bn (BatchNormali (None, 19, 38, 512)  2048        conv3_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_add (Add)          (None, 19, 38, 512)  0           conv3_block1_out[0][0]           \n",
      "                                                                 conv3_block2_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_out (Activation)   (None, 19, 38, 512)  0           conv3_block2_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_conv (Conv2D)    (None, 19, 38, 128)  65664       conv3_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_bn (BatchNormali (None, 19, 38, 128)  512         conv3_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_relu (Activation (None, 19, 38, 128)  0           conv3_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_2_conv (Conv2D)    (None, 19, 38, 128)  147584      conv3_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_2_bn (BatchNormali (None, 19, 38, 128)  512         conv3_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_2_relu (Activation (None, 19, 38, 128)  0           conv3_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_3_conv (Conv2D)    (None, 19, 38, 512)  66048       conv3_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_3_bn (BatchNormali (None, 19, 38, 512)  2048        conv3_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_add (Add)          (None, 19, 38, 512)  0           conv3_block2_out[0][0]           \n",
      "                                                                 conv3_block3_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_out (Activation)   (None, 19, 38, 512)  0           conv3_block3_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_conv (Conv2D)    (None, 19, 38, 128)  65664       conv3_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_bn (BatchNormali (None, 19, 38, 128)  512         conv3_block4_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_relu (Activation (None, 19, 38, 128)  0           conv3_block4_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_2_conv (Conv2D)    (None, 19, 38, 128)  147584      conv3_block4_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_2_bn (BatchNormali (None, 19, 38, 128)  512         conv3_block4_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_2_relu (Activation (None, 19, 38, 128)  0           conv3_block4_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_3_conv (Conv2D)    (None, 19, 38, 512)  66048       conv3_block4_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_3_bn (BatchNormali (None, 19, 38, 512)  2048        conv3_block4_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_add (Add)          (None, 19, 38, 512)  0           conv3_block3_out[0][0]           \n",
      "                                                                 conv3_block4_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_out (Activation)   (None, 19, 38, 512)  0           conv3_block4_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_conv (Conv2D)    (None, 10, 19, 256)  131328      conv3_block4_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_bn (BatchNormali (None, 10, 19, 256)  1024        conv4_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_relu (Activation (None, 10, 19, 256)  0           conv4_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_2_conv (Conv2D)    (None, 10, 19, 256)  590080      conv4_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_2_bn (BatchNormali (None, 10, 19, 256)  1024        conv4_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_2_relu (Activation (None, 10, 19, 256)  0           conv4_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_0_conv (Conv2D)    (None, 10, 19, 1024) 525312      conv3_block4_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_3_conv (Conv2D)    (None, 10, 19, 1024) 263168      conv4_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_0_bn (BatchNormali (None, 10, 19, 1024) 4096        conv4_block1_0_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_3_bn (BatchNormali (None, 10, 19, 1024) 4096        conv4_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_add (Add)          (None, 10, 19, 1024) 0           conv4_block1_0_bn[0][0]          \n",
      "                                                                 conv4_block1_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_out (Activation)   (None, 10, 19, 1024) 0           conv4_block1_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_conv (Conv2D)    (None, 10, 19, 256)  262400      conv4_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_bn (BatchNormali (None, 10, 19, 256)  1024        conv4_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_relu (Activation (None, 10, 19, 256)  0           conv4_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_2_conv (Conv2D)    (None, 10, 19, 256)  590080      conv4_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_2_bn (BatchNormali (None, 10, 19, 256)  1024        conv4_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_2_relu (Activation (None, 10, 19, 256)  0           conv4_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_3_conv (Conv2D)    (None, 10, 19, 1024) 263168      conv4_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_3_bn (BatchNormali (None, 10, 19, 1024) 4096        conv4_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_add (Add)          (None, 10, 19, 1024) 0           conv4_block1_out[0][0]           \n",
      "                                                                 conv4_block2_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_out (Activation)   (None, 10, 19, 1024) 0           conv4_block2_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_conv (Conv2D)    (None, 10, 19, 256)  262400      conv4_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_bn (BatchNormali (None, 10, 19, 256)  1024        conv4_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_relu (Activation (None, 10, 19, 256)  0           conv4_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_2_conv (Conv2D)    (None, 10, 19, 256)  590080      conv4_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_2_bn (BatchNormali (None, 10, 19, 256)  1024        conv4_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_2_relu (Activation (None, 10, 19, 256)  0           conv4_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_3_conv (Conv2D)    (None, 10, 19, 1024) 263168      conv4_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_3_bn (BatchNormali (None, 10, 19, 1024) 4096        conv4_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_add (Add)          (None, 10, 19, 1024) 0           conv4_block2_out[0][0]           \n",
      "                                                                 conv4_block3_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_out (Activation)   (None, 10, 19, 1024) 0           conv4_block3_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_conv (Conv2D)    (None, 10, 19, 256)  262400      conv4_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_bn (BatchNormali (None, 10, 19, 256)  1024        conv4_block4_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_relu (Activation (None, 10, 19, 256)  0           conv4_block4_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_2_conv (Conv2D)    (None, 10, 19, 256)  590080      conv4_block4_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_2_bn (BatchNormali (None, 10, 19, 256)  1024        conv4_block4_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_2_relu (Activation (None, 10, 19, 256)  0           conv4_block4_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_3_conv (Conv2D)    (None, 10, 19, 1024) 263168      conv4_block4_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_3_bn (BatchNormali (None, 10, 19, 1024) 4096        conv4_block4_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_add (Add)          (None, 10, 19, 1024) 0           conv4_block3_out[0][0]           \n",
      "                                                                 conv4_block4_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_out (Activation)   (None, 10, 19, 1024) 0           conv4_block4_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_conv (Conv2D)    (None, 10, 19, 256)  262400      conv4_block4_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_bn (BatchNormali (None, 10, 19, 256)  1024        conv4_block5_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_relu (Activation (None, 10, 19, 256)  0           conv4_block5_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_2_conv (Conv2D)    (None, 10, 19, 256)  590080      conv4_block5_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_2_bn (BatchNormali (None, 10, 19, 256)  1024        conv4_block5_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_2_relu (Activation (None, 10, 19, 256)  0           conv4_block5_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_3_conv (Conv2D)    (None, 10, 19, 1024) 263168      conv4_block5_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_3_bn (BatchNormali (None, 10, 19, 1024) 4096        conv4_block5_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_add (Add)          (None, 10, 19, 1024) 0           conv4_block4_out[0][0]           \n",
      "                                                                 conv4_block5_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_out (Activation)   (None, 10, 19, 1024) 0           conv4_block5_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_conv (Conv2D)    (None, 10, 19, 256)  262400      conv4_block5_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_bn (BatchNormali (None, 10, 19, 256)  1024        conv4_block6_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_relu (Activation (None, 10, 19, 256)  0           conv4_block6_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_2_conv (Conv2D)    (None, 10, 19, 256)  590080      conv4_block6_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_2_bn (BatchNormali (None, 10, 19, 256)  1024        conv4_block6_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_2_relu (Activation (None, 10, 19, 256)  0           conv4_block6_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_3_conv (Conv2D)    (None, 10, 19, 1024) 263168      conv4_block6_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_3_bn (BatchNormali (None, 10, 19, 1024) 4096        conv4_block6_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_add (Add)          (None, 10, 19, 1024) 0           conv4_block5_out[0][0]           \n",
      "                                                                 conv4_block6_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_out (Activation)   (None, 10, 19, 1024) 0           conv4_block6_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_conv (Conv2D)    (None, 5, 10, 512)   524800      conv4_block6_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_bn (BatchNormali (None, 5, 10, 512)   2048        conv5_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_relu (Activation (None, 5, 10, 512)   0           conv5_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_2_conv (Conv2D)    (None, 5, 10, 512)   2359808     conv5_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_2_bn (BatchNormali (None, 5, 10, 512)   2048        conv5_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_2_relu (Activation (None, 5, 10, 512)   0           conv5_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_0_conv (Conv2D)    (None, 5, 10, 2048)  2099200     conv4_block6_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_3_conv (Conv2D)    (None, 5, 10, 2048)  1050624     conv5_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_0_bn (BatchNormali (None, 5, 10, 2048)  8192        conv5_block1_0_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_3_bn (BatchNormali (None, 5, 10, 2048)  8192        conv5_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_add (Add)          (None, 5, 10, 2048)  0           conv5_block1_0_bn[0][0]          \n",
      "                                                                 conv5_block1_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_out (Activation)   (None, 5, 10, 2048)  0           conv5_block1_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_conv (Conv2D)    (None, 5, 10, 512)   1049088     conv5_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_bn (BatchNormali (None, 5, 10, 512)   2048        conv5_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_relu (Activation (None, 5, 10, 512)   0           conv5_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_2_conv (Conv2D)    (None, 5, 10, 512)   2359808     conv5_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_2_bn (BatchNormali (None, 5, 10, 512)   2048        conv5_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_2_relu (Activation (None, 5, 10, 512)   0           conv5_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_3_conv (Conv2D)    (None, 5, 10, 2048)  1050624     conv5_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_3_bn (BatchNormali (None, 5, 10, 2048)  8192        conv5_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_add (Add)          (None, 5, 10, 2048)  0           conv5_block1_out[0][0]           \n",
      "                                                                 conv5_block2_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_out (Activation)   (None, 5, 10, 2048)  0           conv5_block2_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_conv (Conv2D)    (None, 5, 10, 512)   1049088     conv5_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_bn (BatchNormali (None, 5, 10, 512)   2048        conv5_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_relu (Activation (None, 5, 10, 512)   0           conv5_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_2_conv (Conv2D)    (None, 5, 10, 512)   2359808     conv5_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_2_bn (BatchNormali (None, 5, 10, 512)   2048        conv5_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_2_relu (Activation (None, 5, 10, 512)   0           conv5_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_3_conv (Conv2D)    (None, 5, 10, 2048)  1050624     conv5_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_3_bn (BatchNormali (None, 5, 10, 2048)  8192        conv5_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_add (Add)          (None, 5, 10, 2048)  0           conv5_block2_out[0][0]           \n",
      "                                                                 conv5_block3_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_out (Activation)   (None, 5, 10, 2048)  0           conv5_block3_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d (Globa (None, 2048)         0           conv5_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 2048)         0           global_average_pooling2d[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 1024)         2098176     dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 1024)         1049600     dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 9)            9225        dense_1[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 26,744,713\n",
      "Trainable params: 26,691,593\n",
      "Non-trainable params: 53,120\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.models import load_model  \n",
    "from keras.utils import np_utils\n",
    "from keras import applications\n",
    "from keras.preprocessing.image import ImageDataGenerator \n",
    "from keras import optimizers\n",
    "from keras.models import Sequential,Model,load_model\n",
    "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D,GlobalAveragePooling2D\n",
    "from keras.callbacks import TensorBoard,ReduceLROnPlateau,ModelCheckpoint\n",
    "\n",
    "base_model = applications.resnet50.ResNet50(weights= None, include_top=False, input_shape= (150,300,3))\n",
    "\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dropout(0.7)(x)\n",
    "x= Dense(1024, activation= 'relu')(x)\n",
    "x= Dense(1024, activation= 'relu')(x)\n",
    "predictions = Dense(9, activation= 'softmax')(x)\n",
    "model = Model(inputs = base_model.input, outputs = predictions)\n",
    "\n",
    "model.summary()\n",
    "\n",
    "from keras.optimizers import SGD, Adam,Adagrad\n",
    "# sgd = SGD(lr=lrate, momentum=0.9, decay=decay, nesterov=False)\n",
    "adam =Adagrad(lr=0.001)\n",
    "model.compile(optimizer= adam, loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "cw={0: 0.49843931297086175, 1: 1.3119972469565966, 2: 1.5762273901808785, 3: 1.6694033935413246, 4: 1.9178771301012387, 5: 3.4231200897867566, 6: 9.15915915915916, 7: 135.55555555555554, 8: 0.24582104228121926}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "model = keras.models.load_model('C:/Users/Ant Pc/GitHub/AI-in-Mfg---Automated-Driving/Aaftab/ninnanocw.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "SAVING MODEL!\n",
      "  2/225 [..............................] - ETA: 15s - loss: 0.9342 - accuracy: 1.0000WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0130s vs `on_train_batch_end` time: 0.0660s). Check your callbacks.\n",
      "225/225 [==============================] - ETA: 0s - loss: 1.2298 - accuracy: 0.6533WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0050s vs `on_test_batch_end` time: 0.0130s). Check your callbacks.\n",
      "225/225 [==============================] - 17s 77ms/step - loss: 1.2298 - accuracy: 0.6533 - val_loss: 0.8055 - val_accuracy: 0.8400\n"
     ]
    }
   ],
   "source": [
    "EPOCHS=100\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from random import shuffle\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "for d in range(EPOCHS):\n",
    "    data_order = [i for i in range(1,62+1)]\n",
    "    shuffle(data_order)\n",
    "    print(d)\n",
    "    for count,i in enumerate(data_order):\n",
    "        \n",
    "        try:\n",
    "            file_name = 'E:/New folder/Data/niranjan/training_data-{}.npy'.format(i)\n",
    "            # full file info\n",
    "            train_data = np.load(file_name,allow_pickle=True)\n",
    "            \n",
    "            import cv2\n",
    "            X=np.zeros([450,150,300,3])\n",
    "            test_x=np.zeros([50,150,300,3])\n",
    "            \n",
    "            Y=np.zeros([450,9])\n",
    "            test_y=np.zeros([50,9])\n",
    "            for j in range(len(train_data)):\n",
    "                if j < 450:\n",
    "                    a=train_data[j,0]\n",
    "                    a=cv2.resize(a,(300,150))\n",
    "                    X[j]=a\n",
    "                    Y[j]=train_data[j,1]\n",
    "                else:\n",
    "                    a=train_data[j,0]\n",
    "                    a=cv2.resize(a,(300,150))\n",
    "                    test_x[j-450]=a\n",
    "                    test_y[j-450]=train_data[j,1]\n",
    "            \n",
    "            X=np.asarray(X).astype(np.float32)\n",
    "            Y=np.asarray(Y).astype(np.float32)\n",
    "            \n",
    "            test_x=np.asarray(test_x).astype(np.float32)\n",
    "            test_y=np.asarray(test_y).astype(np.float32)\n",
    "            \n",
    "            if i==50:\n",
    "                v=1\n",
    "            else:\n",
    "                v=0\n",
    "            \n",
    "            h=model.fit(X,Y, batch_size=2, epochs = 1, validation_data = (test_x, test_y),verbose=v)\n",
    "            if count%50 == 0:\n",
    "                print('SAVING MODEL!')\n",
    "                model.save('ninnanocw.h5')\n",
    "                    \n",
    "        except Exception as e:\n",
    "            #print(str(e))\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "X=np.zeros([450*61,150,300,3]).astype(np.float16)\n",
    "Y=np.zeros([450*61,150,300,3]).astype(np.float16)\n",
    "\n",
    "test_x=np.zeros([50*61,150,300,3]).astype(np.float16)\n",
    "test_y=np.zeros([50*61,150,300,3]).astype(np.float16)\n",
    "\n",
    "for i in range(63):\n",
    "    try:\n",
    "            print(i)\n",
    "            file_name = 'E:/New folder/Data/niranjan/training_data-{}.npy'.format(i)\n",
    "            # full file info\n",
    "            train_data = np.load(file_name,allow_pickle=True)\n",
    "            \n",
    "            import cv2\n",
    "                \n",
    "            for j in range(len(train_data)):\n",
    "                if j < 450:\n",
    "                    a=train_data[j,0]\n",
    "                    a=cv2.resize(a,(300,150))\n",
    "                    X[i+j]=a\n",
    "                    Y[i+j]=train_data[j,1]\n",
    "                else:\n",
    "                    a=train_data[j,0]\n",
    "                    a=cv2.resize(a,(300,150))\n",
    "                    test_x[i+j-450]=a\n",
    "                    test_y[i+j-450]=train_data[j,1]\n",
    "    \n",
    "    except:\n",
    "        pass\n",
    "X=np.asarray(X).astype(np.float32)\n",
    "Y=np.asarray(Y).astype(np.float32)\n",
    "            \n",
    "test_x=np.asarray(test_x).astype(np.float32)\n",
    "test_y=np.asarray(test_y).astype(np.float32)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from grabscreen import grab_screen\n",
    "import cv2\n",
    "import time\n",
    "from directkeys import PressKey,ReleaseKey, W, A, S, D\n",
    "from getkeys import key_check\n",
    "\n",
    "import random\n",
    "t_time = 0.09\n",
    "\n",
    "def straight():\n",
    "    PressKey(W)\n",
    "    ReleaseKey(A)\n",
    "    ReleaseKey(D)\n",
    "    ReleaseKey(S)\n",
    "\n",
    "def left():\n",
    "    if random.randrange(0,3) == 1:\n",
    "        PressKey(W)\n",
    "    else:\n",
    "        ReleaseKey(W)\n",
    "    PressKey(A)\n",
    "    ReleaseKey(S)\n",
    "    ReleaseKey(D)\n",
    "    #ReleaseKey(S)\n",
    "\n",
    "def right():\n",
    "    if random.randrange(0,3) == 1:\n",
    "        PressKey(W)\n",
    "    else:\n",
    "        ReleaseKey(W)\n",
    "    PressKey(D)\n",
    "    ReleaseKey(A)\n",
    "    ReleaseKey(S)\n",
    "    \n",
    "def reverse():\n",
    "    PressKey(S)\n",
    "    ReleaseKey(A)\n",
    "    ReleaseKey(W)\n",
    "    ReleaseKey(D)\n",
    "\n",
    "\n",
    "def forward_left():\n",
    "    PressKey(W)\n",
    "    PressKey(A)\n",
    "    ReleaseKey(D)\n",
    "    ReleaseKey(S)\n",
    "    \n",
    "    \n",
    "def forward_right():\n",
    "    PressKey(W)\n",
    "    PressKey(D)\n",
    "    ReleaseKey(A)\n",
    "    ReleaseKey(S)\n",
    "\n",
    "    \n",
    "def reverse_left():\n",
    "    PressKey(S)\n",
    "    PressKey(A)\n",
    "    ReleaseKey(W)\n",
    "    ReleaseKey(D)\n",
    "\n",
    "    \n",
    "def reverse_right():\n",
    "    PressKey(S)\n",
    "    PressKey(D)\n",
    "    ReleaseKey(W)\n",
    "    ReleaseKey(A)\n",
    "    \n",
    "def no_keys():\n",
    "\n",
    "    if random.randrange(0,3) == 1:\n",
    "        PressKey(W)\n",
    "    else:\n",
    "        ReleaseKey(W)\n",
    "    ReleaseKey(A)\n",
    "    ReleaseKey(S)\n",
    "    ReleaseKey(D)\n",
    "\n",
    "def main():\n",
    "    last_time = time.time()\n",
    "    for i in list(range(4))[::-1]:\n",
    "        print(i+1)\n",
    "        time.sleep(1)\n",
    "\n",
    "    paused = False\n",
    "    while(True):\n",
    "        \n",
    "        if not paused:\n",
    "            # 800x600 windowed mode\n",
    "            #screen =  np.array(ImageGrab.grab(bbox=(0,40,800,640)))\n",
    "            screen = grab_screen(region=(0,40,3840,2160))\n",
    "            last_time = time.time()\n",
    "            screen = cv2.cvtColor(screen, cv2.COLOR_BGR2GRAY)\n",
    "            screen = cv2.resize(screen, (0,0), fx=0.25, fy=0.25)\n",
    "            screen=cv2.cvtColor(screen,cv2.COLOR_GRAY2RGB)\n",
    "            screen = cv2.resize(screen, (150,300))\n",
    "\n",
    "            prediction = model.predict([screen.reshape(1,150,300,3)])[0]\n",
    "            \n",
    "\n",
    "            mode_choice = np.argmax(prediction)\n",
    "            print(prediction)\n",
    "            if mode_choice == 6:\n",
    "                straight()\n",
    "                choice_picked = 'straight'\n",
    "                \n",
    "            elif mode_choice == 8:\n",
    "                reverse()\n",
    "                choice_picked = 'reverse'\n",
    "                \n",
    "            elif mode_choice == 7:\n",
    "                left()\n",
    "                choice_picked = 'left'\n",
    "            elif mode_choice == 9:\n",
    "                right()\n",
    "                choice_picked = 'right'\n",
    "            elif mode_choice == 0:\n",
    "                forward_left()\n",
    "                choice_picked = 'forward+left'\n",
    "            elif mode_choice == 2:\n",
    "                forward_right()\n",
    "                choice_picked = 'forward+right'\n",
    "            elif mode_choice == 3:\n",
    "                reverse_left()\n",
    "                choice_picked = 'reverse+left'\n",
    "            elif mode_choice == 5:\n",
    "                reverse_right()\n",
    "                choice_picked = 'reverse+right'\n",
    "            else:\n",
    "                no_keys()\n",
    "                print('no')\n",
    "                choice_picked = 'nokeys'\n",
    "\n",
    "        keys = key_check()\n",
    "        print(choice_picked)\n",
    "        # p pauses game and can get annoying.\n",
    "        if 'T' in keys:\n",
    "            if paused:\n",
    "                paused = False\n",
    "                time.sleep(1)\n",
    "            else:\n",
    "                paused = True\n",
    "                ReleaseKey(A)\n",
    "                ReleaseKey(W)\n",
    "                ReleaseKey(D)\n",
    "                time.sleep(1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "3\n",
      "2\n",
      "1\n",
      "[0.09902681 0.1661065  0.09679319 0.13614875 0.13846017 0.04496124\n",
      " 0.04372635 0.0435546  0.23122235]\n",
      "reverse\n",
      "[0.09830917 0.16538471 0.09729707 0.13714941 0.13863993 0.04507538\n",
      " 0.04389849 0.04310289 0.23114297]\n",
      "reverse\n",
      "[0.09945055 0.15982194 0.09789203 0.14109962 0.13098972 0.04365139\n",
      " 0.04405286 0.04593632 0.23710556]\n",
      "reverse\n",
      "[0.09678338 0.16255634 0.09773926 0.14316417 0.13119745 0.04348062\n",
      " 0.0440341  0.04474011 0.23630452]\n",
      "reverse\n",
      "[0.09884741 0.16320512 0.09887989 0.13400537 0.13385579 0.04420288\n",
      " 0.04365776 0.04444088 0.23890483]\n",
      "reverse\n",
      "[0.09891911 0.16162752 0.10071464 0.13624822 0.13374536 0.04469967\n",
      " 0.04293912 0.045443   0.23566337]\n",
      "reverse\n",
      "[0.10086542 0.161675   0.09758291 0.13891055 0.13289542 0.04489152\n",
      " 0.04415299 0.04464012 0.23438601]\n",
      "reverse\n",
      "[0.10100639 0.15886435 0.09887241 0.13333073 0.13229162 0.04416346\n",
      " 0.04431966 0.04371228 0.24343917]\n",
      "reverse\n",
      "[0.09690312 0.16503322 0.09724225 0.13418598 0.13394089 0.04501864\n",
      " 0.04329103 0.04421829 0.24016657]\n",
      "reverse\n",
      "[0.09641945 0.16124083 0.09841855 0.13455513 0.13486668 0.04229432\n",
      " 0.0429096  0.04443435 0.24486116]\n",
      "reverse\n",
      "[0.09773526 0.16517408 0.09743529 0.1365843  0.13665324 0.04297392\n",
      " 0.04382597 0.04525579 0.23436216]\n",
      "reverse\n",
      "[0.09825251 0.16477114 0.09751473 0.13982286 0.12939064 0.0430271\n",
      " 0.04298384 0.04366529 0.24057186]\n",
      "reverse\n",
      "[0.10121953 0.15845914 0.09613696 0.13700972 0.13174054 0.04479999\n",
      " 0.04351274 0.0447486  0.2423728 ]\n",
      "reverse\n",
      "[0.09832821 0.16085653 0.09808438 0.13802479 0.131636   0.04457658\n",
      " 0.04379053 0.04443562 0.2402673 ]\n",
      "reverse\n",
      "[0.09719904 0.16861075 0.09610727 0.13671361 0.13226004 0.04460626\n",
      " 0.04460493 0.04497497 0.23492311]\n",
      "reverse\n",
      "[0.09738274 0.16758434 0.09521366 0.13859968 0.13319145 0.04439356\n",
      " 0.04299501 0.04582271 0.2348169 ]\n",
      "reverse\n",
      "[0.09656484 0.16142143 0.09430228 0.13889527 0.13047321 0.04618327\n",
      " 0.0428972  0.0443399  0.24492264]\n",
      "reverse\n",
      "[0.09680062 0.16198246 0.09616707 0.14052063 0.1327264  0.04441355\n",
      " 0.04221783 0.04412437 0.24104708]\n",
      "reverse\n",
      "[0.09303286 0.16390358 0.09956327 0.1381873  0.13190663 0.04315741\n",
      " 0.04126142 0.04468445 0.24430306]\n",
      "reverse\n",
      "[0.0970379  0.16316673 0.09711217 0.1351794  0.13339339 0.04468387\n",
      " 0.042091   0.04463025 0.24270533]\n",
      "reverse\n",
      "[0.09786603 0.16410592 0.09661787 0.14110485 0.13257022 0.04536022\n",
      " 0.04218832 0.04502211 0.2351645 ]\n",
      "reverse\n",
      "[0.10099821 0.16129656 0.0966099  0.13993354 0.1295189  0.04302471\n",
      " 0.04419497 0.04392195 0.24050124]\n",
      "reverse\n",
      "[0.09866641 0.16186248 0.10002699 0.13798632 0.13044456 0.04457437\n",
      " 0.04294498 0.04368279 0.23981114]\n",
      "reverse\n",
      "[0.09889528 0.16446756 0.09755001 0.13936315 0.13519228 0.0431267\n",
      " 0.04272942 0.04328957 0.23538594]\n",
      "reverse\n",
      "[0.09941108 0.16080855 0.09897645 0.14110155 0.13056177 0.04439511\n",
      " 0.04366066 0.0439047  0.23718011]\n",
      "reverse\n",
      "[0.10064285 0.16068175 0.0975355  0.13740101 0.13621515 0.04276886\n",
      " 0.04417166 0.04417066 0.23641254]\n",
      "reverse\n",
      "[0.09769249 0.16488421 0.09709512 0.13993387 0.13168634 0.04503165\n",
      " 0.04352652 0.04220507 0.23794472]\n",
      "reverse\n",
      "[0.09790908 0.16284443 0.09483041 0.1383306  0.1334672  0.04414628\n",
      " 0.04393994 0.04224151 0.24229048]\n",
      "reverse\n",
      "[0.09781459 0.16326621 0.09751966 0.14009881 0.13191769 0.04531051\n",
      " 0.0428425  0.04279746 0.23843257]\n",
      "reverse\n",
      "[0.10030674 0.16329704 0.09761963 0.13520664 0.13165186 0.04556125\n",
      " 0.04380587 0.04303981 0.2395111 ]\n",
      "reverse\n",
      "[0.10139618 0.15705173 0.09701175 0.13752617 0.13354988 0.04530733\n",
      " 0.04454387 0.04360676 0.2400063 ]\n",
      "reverse\n",
      "[0.10025729 0.15702096 0.09801903 0.1401068  0.13491125 0.04571844\n",
      " 0.04308471 0.04331213 0.23756935]\n",
      "reverse\n",
      "[0.09989021 0.1615117  0.09709194 0.13624993 0.13320084 0.04431003\n",
      " 0.04403397 0.04314765 0.24056372]\n",
      "reverse\n",
      "[0.09993659 0.1602927  0.09848642 0.13838321 0.12934603 0.04490704\n",
      " 0.04221538 0.04384851 0.24258414]\n",
      "reverse\n",
      "[0.1001281  0.16591619 0.09822958 0.13722977 0.13345088 0.04656918\n",
      " 0.04240768 0.04326883 0.23279978]\n",
      "reverse\n",
      "[0.09962168 0.1602572  0.09669573 0.14155316 0.1299035  0.04497826\n",
      " 0.0436645  0.04481246 0.23851356]\n",
      "reverse\n",
      "[0.10172199 0.16482756 0.09652038 0.13117246 0.1306749  0.04416601\n",
      " 0.04276851 0.04408323 0.244065  ]\n",
      "reverse\n",
      "[0.09799539 0.16044714 0.09815708 0.13398091 0.13341337 0.04534546\n",
      " 0.04377178 0.04446922 0.24241959]\n",
      "reverse\n",
      "[0.09888835 0.16286382 0.0964592  0.13701507 0.13080475 0.04453116\n",
      " 0.04479165 0.04374225 0.24090374]\n",
      "reverse\n",
      "[0.0980545  0.1622702  0.0985558  0.13592193 0.1293698  0.04547447\n",
      " 0.04360133 0.04343468 0.24331732]\n",
      "reverse\n",
      "[0.09513853 0.16424929 0.09661426 0.13550174 0.13128595 0.04466851\n",
      " 0.04237496 0.04384248 0.24632429]\n",
      "reverse\n",
      "[0.09819988 0.15787601 0.09799179 0.14013806 0.13555153 0.04353194\n",
      " 0.04177245 0.04365715 0.2412812 ]\n",
      "reverse\n",
      "[0.10037418 0.15954472 0.09656955 0.13790151 0.13234715 0.04492085\n",
      " 0.04378882 0.04351706 0.2410361 ]\n",
      "reverse\n",
      "[0.09529576 0.16181569 0.09856556 0.13485828 0.13489781 0.04517065\n",
      " 0.04383896 0.04356382 0.24199347]\n",
      "reverse\n",
      "[0.09430846 0.1627162  0.09999172 0.13565111 0.13245653 0.04529817\n",
      " 0.04305972 0.04302793 0.24349013]\n",
      "reverse\n",
      "[0.09749848 0.15917432 0.09669594 0.1386759  0.13268746 0.04570424\n",
      " 0.04146203 0.04422421 0.24387734]\n",
      "reverse\n",
      "[0.09758893 0.16354023 0.09635878 0.1390214  0.1285997  0.04364117\n",
      " 0.04292383 0.04389553 0.24443038]\n",
      "reverse\n",
      "[0.09840759 0.16296025 0.09680904 0.13802871 0.13226372 0.04424382\n",
      " 0.04307118 0.04393068 0.24028502]\n",
      "reverse\n",
      "[0.09607401 0.16035816 0.09833029 0.13792662 0.13260867 0.04251651\n",
      " 0.04176406 0.04259252 0.2478292 ]\n",
      "reverse\n",
      "[0.09756938 0.1648534  0.09659872 0.13724808 0.1370568  0.04435619\n",
      " 0.04281088 0.04351648 0.23599008]\n",
      "reverse\n",
      "[0.10092866 0.16244444 0.09814981 0.13801052 0.13179572 0.04473093\n",
      " 0.04288045 0.04289112 0.23816825]\n",
      "reverse\n",
      "[0.10114394 0.16368814 0.09830643 0.1373149  0.12965894 0.04520658\n",
      " 0.04209622 0.04236712 0.24021769]\n",
      "reverse\n",
      "[0.10162241 0.16352586 0.0970025  0.13632338 0.12886557 0.04413285\n",
      " 0.04314079 0.04267578 0.24271081]\n",
      "reverse\n",
      "[0.10158732 0.16048685 0.0966854  0.13676189 0.12969956 0.04285401\n",
      " 0.04402717 0.04258541 0.24531238]\n",
      "reverse\n",
      "[0.10003995 0.16426495 0.09727528 0.13756853 0.13191967 0.04368926\n",
      " 0.04416787 0.04343397 0.23764063]\n",
      "reverse\n",
      "[0.10070007 0.1634773  0.10197588 0.13733748 0.12926367 0.04419326\n",
      " 0.04320717 0.04451882 0.23532638]\n",
      "reverse\n",
      "[0.10060117 0.16114962 0.09649786 0.13711087 0.13414559 0.04281991\n",
      " 0.04430911 0.04463677 0.23872912]\n",
      "reverse\n",
      "[0.10016516 0.16496828 0.09929902 0.1342536  0.13401891 0.04355881\n",
      " 0.04358927 0.04391446 0.23623252]\n",
      "reverse\n",
      "[0.09997945 0.15952045 0.09725162 0.13794322 0.12751439 0.04285357\n",
      " 0.04490738 0.04466942 0.24536051]\n",
      "reverse\n",
      "[0.09966952 0.16344915 0.09750026 0.13880032 0.12841493 0.04323239\n",
      " 0.0441428  0.04371317 0.24107745]\n",
      "reverse\n",
      "[0.09939855 0.16380951 0.09626324 0.13628858 0.1370775  0.04260044\n",
      " 0.04276861 0.04277173 0.23902188]\n",
      "reverse\n",
      "[0.09898895 0.16410163 0.09710176 0.13597631 0.1328973  0.04486107\n",
      " 0.0429436  0.04362529 0.23950416]\n",
      "reverse\n",
      "[0.10399907 0.16353318 0.09610964 0.14095522 0.13326679 0.04575491\n",
      " 0.04432938 0.04306483 0.22898698]\n",
      "reverse\n",
      "[0.10150257 0.16259149 0.09599842 0.14464653 0.13024223 0.04462149\n",
      " 0.04422482 0.04485065 0.23132187]\n",
      "reverse\n",
      "[0.1004246  0.16265474 0.09686416 0.13664554 0.12829767 0.04393321\n",
      " 0.04390511 0.04481748 0.24245737]\n",
      "reverse\n",
      "[0.09795446 0.16335502 0.0958022  0.13638593 0.13575874 0.04409079\n",
      " 0.04309762 0.04398657 0.2395687 ]\n",
      "reverse\n",
      "[0.10279476 0.16088441 0.09864417 0.13680786 0.13086186 0.04498462\n",
      " 0.04398995 0.04420036 0.23683207]\n",
      "reverse\n",
      "[0.10068226 0.16130231 0.09900185 0.13427822 0.13101003 0.04465578\n",
      " 0.04394652 0.04514832 0.23997472]\n",
      "reverse\n",
      "[0.09926899 0.16038153 0.09785353 0.13880701 0.13170116 0.04470377\n",
      " 0.04229615 0.04372866 0.24125925]\n",
      "reverse\n",
      "[0.0979123  0.16295382 0.09649189 0.13678268 0.13250558 0.04319858\n",
      " 0.04363906 0.04363152 0.24288459]\n",
      "reverse\n",
      "[0.09960016 0.16393246 0.09619408 0.13545768 0.13420069 0.04396536\n",
      " 0.04451462 0.04444755 0.23768745]\n",
      "reverse\n",
      "[0.09890045 0.16251545 0.09825616 0.13704045 0.13156979 0.04457774\n",
      " 0.04255226 0.04339943 0.24118835]\n",
      "reverse\n",
      "[0.1019922  0.16389251 0.09807948 0.13640933 0.12776865 0.04489838\n",
      " 0.04294648 0.04372773 0.2402852 ]\n",
      "reverse\n",
      "[0.09823506 0.1649975  0.09607752 0.13826554 0.13195907 0.04500834\n",
      " 0.04377553 0.04449921 0.23718229]\n",
      "reverse\n",
      "[0.09854305 0.16084053 0.0956819  0.1411562  0.1322601  0.04439193\n",
      " 0.04373181 0.04382502 0.23956949]\n",
      "reverse\n",
      "[0.10010711 0.16432948 0.09745565 0.13707004 0.13031062 0.04527346\n",
      " 0.04424801 0.0439086  0.23729701]\n",
      "reverse\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0994954  0.16804244 0.09458641 0.13904403 0.12973076 0.04317983\n",
      " 0.04289288 0.04241993 0.24060832]\n",
      "reverse\n",
      "[0.1018014  0.1662132  0.09782597 0.13999347 0.13148406 0.04408449\n",
      " 0.04259788 0.04474756 0.23125197]\n",
      "reverse\n",
      "[0.09868585 0.16133192 0.0997984  0.13584933 0.13042961 0.04423433\n",
      " 0.0435038  0.04544244 0.24072435]\n",
      "reverse\n",
      "[0.09756946 0.167661   0.09577265 0.13749343 0.13681492 0.04380642\n",
      " 0.04375882 0.04355972 0.23356363]\n",
      "reverse\n",
      "[0.10522928 0.1665494  0.09877789 0.13301285 0.1307735  0.04285544\n",
      " 0.04340615 0.04454991 0.23484561]\n",
      "reverse\n",
      "[0.1021333  0.16584785 0.09385161 0.13741569 0.13577837 0.04362746\n",
      " 0.04300458 0.04340623 0.2349349 ]\n",
      "reverse\n",
      "[0.10344262 0.16686012 0.09566344 0.1368464  0.13365343 0.04306937\n",
      " 0.04356875 0.04290109 0.23399478]\n",
      "reverse\n",
      "[0.09678572 0.16480337 0.09635383 0.13363865 0.13422985 0.04300112\n",
      " 0.04386791 0.04408428 0.24323532]\n",
      "reverse\n",
      "[0.09689014 0.1623386  0.09728291 0.13870734 0.13270545 0.04304282\n",
      " 0.04360845 0.04380715 0.24161714]\n",
      "reverse\n",
      "[0.09865637 0.16315088 0.09601021 0.14199245 0.13027589 0.04401598\n",
      " 0.04418512 0.04405327 0.23765981]\n",
      "reverse\n",
      "[0.09685091 0.16591282 0.09563293 0.13835523 0.1315886  0.04533393\n",
      " 0.04441465 0.04473133 0.23717965]\n",
      "reverse\n",
      "[0.09878045 0.16622257 0.09750072 0.1382907  0.12794684 0.04437612\n",
      " 0.04351557 0.04352    0.23984703]\n",
      "reverse\n",
      "[0.10102053 0.16411085 0.09655204 0.13652954 0.13248943 0.04466097\n",
      " 0.04402114 0.04346848 0.23714705]\n",
      "reverse\n",
      "[0.10003541 0.16085437 0.09880293 0.1373436  0.13109732 0.04268278\n",
      " 0.04423961 0.04450449 0.24043952]\n",
      "reverse\n",
      "[0.09768022 0.16262297 0.0979133  0.13765812 0.13510385 0.04397252\n",
      " 0.04430472 0.04384445 0.23689978]\n",
      "reverse\n",
      "[0.09568717 0.16190457 0.09581149 0.13714829 0.13306217 0.04371976\n",
      " 0.04340697 0.04372916 0.24553046]\n",
      "reverse\n",
      "[0.10075828 0.16185619 0.09687367 0.1411459  0.13213436 0.04324315\n",
      " 0.04420541 0.04372571 0.23605736]\n",
      "reverse\n",
      "[0.09915596 0.16511995 0.0971153  0.1371971  0.13572237 0.04471332\n",
      " 0.04317849 0.04374735 0.23405017]\n",
      "reverse\n",
      "[0.0964234  0.16135427 0.09827624 0.13943034 0.13427664 0.04421306\n",
      " 0.04312706 0.0421329  0.24076605]\n",
      "reverse\n",
      "[0.09819606 0.1638931  0.09880227 0.13813294 0.13398135 0.04332186\n",
      " 0.04326452 0.04285147 0.23755643]\n",
      "reverse\n",
      "[0.09588161 0.16021053 0.10048534 0.13802138 0.13390936 0.04243062\n",
      " 0.04355085 0.04316516 0.24234508]\n",
      "reverse\n",
      "[0.09958059 0.16299696 0.09689926 0.14045176 0.13077945 0.04412016\n",
      " 0.0435702  0.04295599 0.23864564]\n",
      "reverse\n",
      "[0.09630375 0.16729604 0.09431784 0.1412312  0.13339038 0.0436063\n",
      " 0.0430701  0.04308513 0.23769924]\n",
      "reverse\n",
      "[0.0984566  0.16187033 0.09755994 0.13758293 0.13482465 0.0447527\n",
      " 0.04224159 0.04297901 0.23973222]\n",
      "reverse\n",
      "[0.09745475 0.16089778 0.09617692 0.14427336 0.13401105 0.04381088\n",
      " 0.04329435 0.04305851 0.23702236]\n",
      "reverse\n",
      "[0.09866063 0.16399896 0.09603713 0.14070517 0.1307106  0.04502414\n",
      " 0.04358198 0.04352176 0.23775972]\n",
      "reverse\n",
      "[0.09721003 0.16362374 0.09582593 0.13732135 0.13265887 0.04294005\n",
      " 0.04307116 0.04347251 0.24387644]\n",
      "reverse\n",
      "[0.10110682 0.16655692 0.09901875 0.13645387 0.12919734 0.04353329\n",
      " 0.04384097 0.04350749 0.2367846 ]\n",
      "reverse\n",
      "[0.09599455 0.16450788 0.09861561 0.13943411 0.13323525 0.04323554\n",
      " 0.04355436 0.04294266 0.23848002]\n",
      "reverse\n",
      "[0.09789346 0.16909644 0.0962792  0.13856629 0.1298252  0.04243346\n",
      " 0.04198387 0.04468229 0.23923972]\n",
      "reverse\n",
      "[0.0990851  0.16615565 0.09769921 0.13603477 0.13271116 0.04295749\n",
      " 0.04291756 0.04347377 0.23896529]\n",
      "reverse\n",
      "[0.09661483 0.16154332 0.09680711 0.14324543 0.12834339 0.04463679\n",
      " 0.0440541  0.04336423 0.24139087]\n",
      "reverse\n",
      "[0.09689059 0.16253988 0.09454886 0.13783108 0.13066877 0.04405961\n",
      " 0.044562   0.04418679 0.2447124 ]\n",
      "reverse\n",
      "[0.1002303  0.16075821 0.09818871 0.13956523 0.13101639 0.04459048\n",
      " 0.04450921 0.04325889 0.23788257]\n",
      "reverse\n",
      "[0.09784611 0.16293839 0.09661091 0.13862953 0.1284944  0.04546615\n",
      " 0.0451491  0.04398036 0.24088499]\n",
      "reverse\n",
      "[0.10006766 0.15970746 0.09905154 0.13985854 0.13031122 0.04495244\n",
      " 0.04298519 0.04357764 0.23948835]\n",
      "reverse\n",
      "[0.10231014 0.16243438 0.09684782 0.13683443 0.1321051  0.04411958\n",
      " 0.04368204 0.04379884 0.23786767]\n",
      "reverse\n",
      "[0.08093674 0.08944616 0.02119916 0.12009589 0.09720769 0.00222989\n",
      " 0.0072009  0.00656433 0.57511926]\n",
      "reverse\n",
      "[0.07901174 0.0879158  0.02108094 0.12131339 0.09572334 0.00219092\n",
      " 0.00708352 0.00651214 0.57916826]\n",
      "reverse\n",
      "[0.07854606 0.08686113 0.02049701 0.12196462 0.09472911 0.00215229\n",
      " 0.00695232 0.00646626 0.5818313 ]\n",
      "reverse\n",
      "[0.07776465 0.0881047  0.02026686 0.12169428 0.09523576 0.00213961\n",
      " 0.00700517 0.0064831  0.5813059 ]\n",
      "reverse\n",
      "[0.0791751  0.08848087 0.02101702 0.12140483 0.09648415 0.002217\n",
      " 0.00711709 0.00647189 0.577632  ]\n",
      "reverse\n",
      "[0.07963136 0.08857058 0.02106437 0.1216401  0.0968482  0.00221823\n",
      " 0.00712461 0.00647109 0.5764315 ]\n",
      "reverse\n",
      "[0.07962318 0.08858076 0.02106211 0.12171467 0.0968503  0.00221878\n",
      " 0.00712488 0.0064719  0.5763534 ]\n",
      "reverse\n",
      "[0.07962318 0.08858076 0.02106211 0.12171467 0.0968503  0.00221878\n",
      " 0.00712488 0.0064719  0.5763534 ]\n",
      "reverse\n",
      "[0.07899184 0.08860818 0.02031951 0.1200361  0.09458014 0.0021599\n",
      " 0.00695951 0.00633016 0.5820147 ]\n",
      "reverse\n",
      "[0.08199691 0.09468278 0.02442938 0.1229546  0.1023539  0.00273707\n",
      " 0.00821685 0.00827771 0.5543508 ]\n",
      "reverse\n",
      "[0.08916726 0.09462336 0.02680469 0.13006356 0.10432627 0.00307651\n",
      " 0.00912005 0.00841482 0.5344035 ]\n",
      "reverse\n",
      "[0.08779957 0.09436518 0.02578711 0.12956016 0.10310085 0.00297222\n",
      " 0.00875882 0.00816649 0.5394896 ]\n",
      "reverse\n",
      "[0.08915237 0.09466916 0.02682125 0.13013826 0.10425839 0.00307621\n",
      " 0.00912027 0.00841286 0.5343512 ]\n",
      "reverse\n",
      "[0.0863038  0.09806948 0.0244547  0.130586   0.10746051 0.00289761\n",
      " 0.00867538 0.00776433 0.53378814]\n",
      "reverse\n",
      "[0.08719934 0.08885141 0.02464288 0.13114639 0.10572618 0.00283488\n",
      " 0.00830224 0.00828178 0.54301494]\n",
      "reverse\n",
      "[0.07968025 0.09099171 0.01988471 0.12383475 0.09727731 0.00211185\n",
      " 0.00716848 0.00620737 0.5728436 ]\n",
      "reverse\n",
      "[0.08149434 0.09021442 0.02285702 0.13122384 0.10083423 0.00248742\n",
      " 0.00786494 0.00746242 0.55556136]\n",
      "reverse\n",
      "[0.08468742 0.09573605 0.0241183  0.12925963 0.10506912 0.00277009\n",
      " 0.00839933 0.00764446 0.5423156 ]\n",
      "reverse\n",
      "[0.0862145  0.09111228 0.02280721 0.1150857  0.10109346 0.00259424\n",
      " 0.00809975 0.00743626 0.5655565 ]\n",
      "reverse\n",
      "[0.08716862 0.09159269 0.0230277  0.11511071 0.10070278 0.00260656\n",
      " 0.00816321 0.00753971 0.564088  ]\n",
      "reverse\n",
      "[0.0836887  0.08665562 0.02038715 0.12537432 0.10245566 0.00211496\n",
      " 0.00662731 0.00629689 0.5663994 ]\n",
      "reverse\n",
      "[0.08059681 0.08776824 0.01981531 0.11777492 0.10228484 0.00207882\n",
      " 0.00665012 0.00595103 0.5770799 ]\n",
      "reverse\n",
      "[0.07927293 0.08720458 0.01915653 0.12163679 0.10256906 0.0021497\n",
      " 0.00652286 0.00582106 0.5756665 ]\n",
      "reverse\n",
      "[0.08334322 0.0958138  0.02309027 0.1315846  0.10378382 0.00267241\n",
      " 0.00798269 0.00760497 0.54412425]\n",
      "reverse\n",
      "[0.08953642 0.09560934 0.02814857 0.12538888 0.10684153 0.0029341\n",
      " 0.00897572 0.00847662 0.5340888 ]\n",
      "reverse\n",
      "[0.08178758 0.09460731 0.02300223 0.12056345 0.10274597 0.00275218\n",
      " 0.00844784 0.00788961 0.5582038 ]\n",
      "reverse\n",
      "[0.08160827 0.09438772 0.02308187 0.12055831 0.10259541 0.00276068\n",
      " 0.00847032 0.00790311 0.5586343 ]\n",
      "reverse\n",
      "[0.0795543  0.08824249 0.01930114 0.12487478 0.10242929 0.00200339\n",
      " 0.00621304 0.00552447 0.5718571 ]\n",
      "reverse\n",
      "[0.07983322 0.08825445 0.02341802 0.12545858 0.10085002 0.0026636\n",
      " 0.00788238 0.00767734 0.5639624 ]\n",
      "reverse\n",
      "[0.08204101 0.08971914 0.01918979 0.12173962 0.0987656  0.00199362\n",
      " 0.00633137 0.00607407 0.5741458 ]\n",
      "reverse\n",
      "[0.07892331 0.09012299 0.01854438 0.12618913 0.09750745 0.00203445\n",
      " 0.00669889 0.00590145 0.57407796]\n",
      "reverse\n",
      "[0.08531784 0.09195808 0.02353923 0.12599961 0.10875393 0.00282446\n",
      " 0.00847207 0.00799142 0.54514337]\n",
      "reverse\n",
      "[0.07927413 0.09020789 0.02152018 0.12682293 0.10443609 0.00244097\n",
      " 0.00757295 0.00728392 0.560441  ]\n",
      "reverse\n",
      "[0.07945025 0.09084781 0.02136453 0.12684807 0.10498878 0.00244496\n",
      " 0.00755437 0.00726335 0.5592379 ]\n",
      "reverse\n",
      "[0.08684428 0.09014318 0.02442078 0.12998524 0.10544794 0.00274413\n",
      " 0.00803605 0.007615   0.5447634 ]\n",
      "reverse\n",
      "[0.08433183 0.09462469 0.02280053 0.12537827 0.10133778 0.0025052\n",
      " 0.00736699 0.0075446  0.55411005]\n",
      "reverse\n",
      "[0.07923406 0.0887539  0.02109642 0.11968993 0.10012831 0.00256354\n",
      " 0.00757093 0.00724301 0.57371986]\n",
      "reverse\n",
      "[0.08548722 0.08911648 0.02163639 0.12397502 0.10173639 0.00239424\n",
      " 0.00756964 0.00688631 0.56119835]\n",
      "reverse\n",
      "[0.08454691 0.08924548 0.02145184 0.1253915  0.1025209  0.00235193\n",
      " 0.00747582 0.00678989 0.5602258 ]\n",
      "reverse\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.08454691 0.08924548 0.02145184 0.1253915  0.1025209  0.00235193\n",
      " 0.00747582 0.00678989 0.5602258 ]\n",
      "reverse\n",
      "[0.08461478 0.08948359 0.02146613 0.12573814 0.10281527 0.00235249\n",
      " 0.00747079 0.00679244 0.5592664 ]\n",
      "reverse\n",
      "[0.0882706  0.09409508 0.02495684 0.12606862 0.10801208 0.00281333\n",
      " 0.00835581 0.00783221 0.5395954 ]\n",
      "reverse\n",
      "[0.08250627 0.08569168 0.02063872 0.13387771 0.10210742 0.00286422\n",
      " 0.00809516 0.00791051 0.5563083 ]\n",
      "reverse\n",
      "[0.07307293 0.08074009 0.01982583 0.13424169 0.10174063 0.00223952\n",
      " 0.00781731 0.0069331  0.57338893]\n",
      "reverse\n",
      "[0.07609072 0.08205483 0.01780247 0.12679483 0.0964337  0.00207422\n",
      " 0.00650309 0.00667875 0.58556736]\n",
      "reverse\n",
      "[0.07902723 0.08112954 0.02017923 0.1284976  0.10072276 0.0024136\n",
      " 0.00775194 0.00804807 0.57223004]\n",
      "reverse\n",
      "[0.07274141 0.0802788  0.01980968 0.13435806 0.1009546  0.00224564\n",
      " 0.00777174 0.00694202 0.574898  ]\n",
      "reverse\n",
      "[0.07288812 0.08061079 0.01993859 0.13454017 0.10140473 0.00225959\n",
      " 0.00781299 0.00697876 0.57356626]\n",
      "reverse\n",
      "[0.0732291  0.08047017 0.01977126 0.13516411 0.10102069 0.00225046\n",
      " 0.00766123 0.00689943 0.5735336 ]\n",
      "reverse\n",
      "[0.0732291  0.08047017 0.01977126 0.13516411 0.10102069 0.00225046\n",
      " 0.00766123 0.00689943 0.5735336 ]\n",
      "reverse\n",
      "[0.07302986 0.08040336 0.01987579 0.1343424  0.10129964 0.00225618\n",
      " 0.00776873 0.00695924 0.5740648 ]\n",
      "reverse\n",
      "[0.07302986 0.08040336 0.01987579 0.1343424  0.10129964 0.00225618\n",
      " 0.00776873 0.00695924 0.5740648 ]\n",
      "reverse\n",
      "[0.0729183  0.08027814 0.01994785 0.13460399 0.10135865 0.00225642\n",
      " 0.00778742 0.00698382 0.5738654 ]\n",
      "reverse\n",
      "[0.07261945 0.07990009 0.01998194 0.13464619 0.1013754  0.00224507\n",
      " 0.0077568  0.00697062 0.57450444]\n",
      "reverse\n",
      "[0.07421017 0.08046248 0.02034609 0.13403934 0.10228889 0.00229757\n",
      " 0.00783774 0.00709835 0.57141936]\n",
      "reverse\n",
      "[0.07653303 0.07956865 0.02028556 0.13591036 0.10081213 0.00224206\n",
      " 0.00745943 0.00693265 0.5702561 ]\n",
      "reverse\n",
      "[0.07555524 0.07961799 0.02013089 0.1363595  0.10221142 0.00222619\n",
      " 0.00741109 0.00684598 0.5696417 ]\n",
      "reverse\n",
      "[0.07485098 0.07963711 0.0204416  0.13667683 0.10120521 0.0022041\n",
      " 0.00752155 0.00691409 0.5705486 ]\n",
      "reverse\n",
      "[0.07580685 0.07945266 0.02016533 0.1355457  0.10261828 0.00223761\n",
      " 0.00738614 0.00689054 0.5698968 ]\n",
      "reverse\n",
      "[0.07462042 0.07978138 0.02044665 0.13683154 0.10145899 0.00220157\n",
      " 0.0074321  0.00689204 0.5703353 ]\n",
      "reverse\n",
      "[0.07582206 0.07944446 0.020186   0.13627972 0.1026933  0.00223608\n",
      " 0.00741264 0.00686974 0.569056  ]\n",
      "reverse\n",
      "[0.07442016 0.07926969 0.02039877 0.13727197 0.10090642 0.00220141\n",
      " 0.00750132 0.00689558 0.5711346 ]\n",
      "reverse\n",
      "[0.07546043 0.07884324 0.020068   0.13533698 0.10087707 0.00220719\n",
      " 0.00744048 0.00685902 0.57290757]\n",
      "reverse\n",
      "[0.08148538 0.11335512 0.07112345 0.15157968 0.1057926  0.0142914\n",
      " 0.02426511 0.04000156 0.3981057 ]\n",
      "reverse\n",
      "[0.0912035  0.18898013 0.10576674 0.13998276 0.13627335 0.04939448\n",
      " 0.03850772 0.03879797 0.21109335]\n",
      "reverse\n",
      "[0.096033   0.17230745 0.09833281 0.14266853 0.1368217  0.04955148\n",
      " 0.041557   0.04420756 0.2185205 ]\n",
      "reverse\n",
      "[0.09526807 0.17313933 0.09819541 0.14259475 0.1367457  0.04897555\n",
      " 0.04183485 0.04396688 0.21927951]\n",
      "reverse\n",
      "[0.09526807 0.17313933 0.09819541 0.14259475 0.1367457  0.04897555\n",
      " 0.04183485 0.04396688 0.21927951]\n",
      "reverse\n",
      "[0.09488732 0.1729663  0.09831784 0.14365116 0.13719141 0.04892921\n",
      " 0.04201759 0.04378636 0.21825276]\n",
      "reverse\n",
      "[0.09528022 0.17314862 0.09820444 0.14257641 0.13670725 0.04896829\n",
      " 0.04183965 0.04397298 0.21930207]\n",
      "reverse\n",
      "[0.09530458 0.17312546 0.09815628 0.1425662  0.13678186 0.04892527\n",
      " 0.04185535 0.04399331 0.21929164]\n",
      "reverse\n"
     ]
    }
   ],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sssssssssssssssssssssssssssssssssssssssssssssssssssssss"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
