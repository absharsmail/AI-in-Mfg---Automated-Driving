{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "#imports necessary to define a neural network \n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "#ensure you are using GPU.\n",
    "if torch.cuda.is_available():  \n",
    "  dev = \"cuda:0\" \n",
    "else:  \n",
    "  dev = \"cpu\"  \n",
    "\n",
    "device = torch.device(dev)\n",
    "print(device)\n",
    "\n",
    "dtype = torch.cuda.FloatTensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in C:\\Users\\Ant Pc/.cache\\torch\\hub\\pytorch_vision_master\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AlexNet(\n",
       "  (features): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(11, 11), stride=(4, 4), padding=(2, 2))\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (3): Conv2d(64, 192, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "    (4): ReLU(inplace=True)\n",
       "    (5): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (6): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (7): ReLU(inplace=True)\n",
       "    (8): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (9): ReLU(inplace=True)\n",
       "    (10): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (11): ReLU(inplace=True)\n",
       "    (12): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(6, 6))\n",
       "  (classifier): Sequential(\n",
       "    (0): Dropout(p=0.5, inplace=False)\n",
       "    (1): Linear(in_features=9216, out_features=4096, bias=True)\n",
       "    (2): ReLU(inplace=True)\n",
       "    (3): Dropout(p=0.5, inplace=False)\n",
       "    (4): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "    (5): ReLU(inplace=True)\n",
       "    (6): Linear(in_features=4096, out_features=1000, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = torch.hub.load('pytorch/vision', 'alexnet', pretrained=False,force_reload=False)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AlexNet(\n",
       "  (features): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(11, 11), stride=(4, 4), padding=(2, 2))\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (3): Conv2d(64, 192, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "    (4): ReLU(inplace=True)\n",
       "    (5): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (6): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (7): ReLU(inplace=True)\n",
       "    (8): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (9): ReLU(inplace=True)\n",
       "    (10): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (11): ReLU(inplace=True)\n",
       "    (12): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(6, 6))\n",
       "  (classifier): Sequential(\n",
       "    (0): Dropout(p=0.5, inplace=False)\n",
       "    (1): Linear(in_features=9216, out_features=4096, bias=True)\n",
       "    (2): ReLU(inplace=True)\n",
       "    (3): Dropout(p=0.5, inplace=False)\n",
       "    (4): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "    (5): ReLU(inplace=True)\n",
       "    (6): Linear(in_features=4096, out_features=9, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import cv2\n",
    "model.classifier[6]=nn.Linear(4096,9)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.load_state_dict(torch.load('C:/Users/Ant Pc/GitHub/AI-in-Mfg---Automated-Driving/Aaftab/vijresnet152balance.pt'))\n",
    "model=model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "trdt1=np.load('C:/Users/Ant Pc/GitHub/AI-in-Mfg---Automated-Driving/d.npy', allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "trdt=np.load('C:/Users/Ant Pc/GitHub/AI-in-Mfg---Automated-Driving/s.npy', allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "EOFError",
     "evalue": "Ran out of input",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mEOFError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-cbcdea2394ff>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtrdt2\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'C:/Users/Ant Pc/GitHub/AI-in-Mfg---Automated-Driving/a.npy'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mallow_pickle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\numpy\\lib\\npyio.py\u001b[0m in \u001b[0;36mload\u001b[1;34m(file, mmap_mode, allow_pickle, fix_imports, encoding)\u001b[0m\n\u001b[0;32m    450\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mformat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen_memmap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmmap_mode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    451\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 452\u001b[1;33m                 return format.read_array(fid, allow_pickle=allow_pickle,\n\u001b[0m\u001b[0;32m    453\u001b[0m                                          pickle_kwargs=pickle_kwargs)\n\u001b[0;32m    454\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\numpy\\lib\\format.py\u001b[0m in \u001b[0;36mread_array\u001b[1;34m(fp, allow_pickle, pickle_kwargs)\u001b[0m\n\u001b[0;32m    742\u001b[0m             \u001b[0mpickle_kwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    743\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 744\u001b[1;33m             \u001b[0marray\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mpickle_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    745\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mUnicodeError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    746\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mversion_info\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m>=\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mEOFError\u001b[0m: Ran out of input"
     ]
    }
   ],
   "source": [
    "trdt2=np.load('C:/Users/Ant Pc/GitHub/AI-in-Mfg---Automated-Driving/w.npy', allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_X=[]\n",
    "val_Y=[]\n",
    "np.random.shuffle(trdt1)\n",
    "val_X=trdt1[:,0]\n",
    "val_Y=trdt1[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0134) tensor(0.3187, device='cuda:0', dtype=torch.float64) 0 339.5377767086029 89400\n",
      "tensor(0.0146, device='cuda:0') tensor(0.4340, device='cuda:0', dtype=torch.float64)\n",
      "tensor(0.0062) tensor(0.4331, device='cuda:0', dtype=torch.float64) 1 331.918306350708 89400\n",
      "tensor(0.0184, device='cuda:0') tensor(0.3984, device='cuda:0', dtype=torch.float64)\n",
      "tensor(0.0056) tensor(0.4531, device='cuda:0', dtype=torch.float64) 2 329.55335569381714 89400\n",
      "tensor(0.0077, device='cuda:0') tensor(0.3604, device='cuda:0', dtype=torch.float64)\n",
      "tensor(0.0051) tensor(0.4683, device='cuda:0', dtype=torch.float64) 3 336.8823263645172 89400\n",
      "tensor(0.0304, device='cuda:0') tensor(0.4604, device='cuda:0', dtype=torch.float64)\n",
      "tensor(0.0048) tensor(0.4790, device='cuda:0', dtype=torch.float64) 4 332.7974681854248 89400\n",
      "tensor(0.0238, device='cuda:0') tensor(0.3720, device='cuda:0', dtype=torch.float64)\n",
      "tensor(0.0045) tensor(0.4919, device='cuda:0', dtype=torch.float64) 5 332.4849202632904 89400\n",
      "tensor(0.0272, device='cuda:0') tensor(0.4382, device='cuda:0', dtype=torch.float64)\n",
      "tensor(0.0042) tensor(0.4998, device='cuda:0', dtype=torch.float64) 6 336.50311064720154 89400\n",
      "tensor(0.0420, device='cuda:0') tensor(0.4176, device='cuda:0', dtype=torch.float64)\n",
      "tensor(0.0039) tensor(0.5144, device='cuda:0', dtype=torch.float64) 7 338.4434885978699 89400\n",
      "tensor(0.0472, device='cuda:0') tensor(0.3876, device='cuda:0', dtype=torch.float64)\n",
      "tensor(0.0037) tensor(0.5231, device='cuda:0', dtype=torch.float64) 8 339.77617502212524 89400\n",
      "tensor(0.0367, device='cuda:0') tensor(0.3947, device='cuda:0', dtype=torch.float64)\n",
      "tensor(0.0035) tensor(0.5373, device='cuda:0', dtype=torch.float64) 9 341.48811864852905 89400\n",
      "tensor(0.0504, device='cuda:0') tensor(0.3984, device='cuda:0', dtype=torch.float64)\n",
      "tensor(0.0033) tensor(0.5491, device='cuda:0', dtype=torch.float64) 10 342.7191197872162 89400\n",
      "tensor(0.0442, device='cuda:0') tensor(0.4204, device='cuda:0', dtype=torch.float64)\n",
      "tensor(0.0031) tensor(0.5636, device='cuda:0', dtype=torch.float64) 11 345.08932065963745 89400\n",
      "tensor(0.0472, device='cuda:0') tensor(0.4324, device='cuda:0', dtype=torch.float64)\n",
      "tensor(0.0029) tensor(0.5780, device='cuda:0', dtype=torch.float64) 12 346.03362798690796 89400\n",
      "tensor(0.0452, device='cuda:0') tensor(0.4149, device='cuda:0', dtype=torch.float64)\n",
      "tensor(0.0027) tensor(0.5925, device='cuda:0', dtype=torch.float64) 13 345.543479681015 89400\n",
      "tensor(0.0513, device='cuda:0') tensor(0.4233, device='cuda:0', dtype=torch.float64)\n",
      "tensor(0.0026) tensor(0.6103, device='cuda:0', dtype=torch.float64) 14 360.82047510147095 89400\n",
      "tensor(0.0410, device='cuda:0') tensor(0.4433, device='cuda:0', dtype=torch.float64)\n",
      "tensor(0.0024) tensor(0.6292, device='cuda:0', dtype=torch.float64) 15 347.9604318141937 89400\n",
      "tensor(0.0510, device='cuda:0') tensor(0.3969, device='cuda:0', dtype=torch.float64)\n",
      "tensor(0.0023) tensor(0.6449, device='cuda:0', dtype=torch.float64) 16 350.3991267681122 89400\n",
      "tensor(0.0411, device='cuda:0') tensor(0.4827, device='cuda:0', dtype=torch.float64)\n",
      "tensor(0.0021) tensor(0.6654, device='cuda:0', dtype=torch.float64) 17 350.1026394367218 89400\n",
      "tensor(0.0551, device='cuda:0') tensor(0.4484, device='cuda:0', dtype=torch.float64)\n",
      "tensor(0.0020) tensor(0.6852, device='cuda:0', dtype=torch.float64) 18 351.4799222946167 89400\n",
      "tensor(0.0585, device='cuda:0') tensor(0.4211, device='cuda:0', dtype=torch.float64)\n",
      "tensor(0.0018) tensor(0.7032, device='cuda:0', dtype=torch.float64) 19 353.6579747200012 89400\n",
      "tensor(0.0511, device='cuda:0') tensor(0.4560, device='cuda:0', dtype=torch.float64)\n",
      "tensor(0.0017) tensor(0.7233, device='cuda:0', dtype=torch.float64) 20 353.47229194641113 89400\n",
      "tensor(0.0541, device='cuda:0') tensor(0.4576, device='cuda:0', dtype=torch.float64)\n",
      "tensor(0.0015) tensor(0.7447, device='cuda:0', dtype=torch.float64) 21 355.4186520576477 89400\n",
      "tensor(0.0489, device='cuda:0') tensor(0.4764, device='cuda:0', dtype=torch.float64)\n",
      "tensor(0.0014) tensor(0.7606, device='cuda:0', dtype=torch.float64) 22 355.36200165748596 89400\n",
      "tensor(0.0516, device='cuda:0') tensor(0.4833, device='cuda:0', dtype=torch.float64)\n",
      "tensor(0.0013) tensor(0.7813, device='cuda:0', dtype=torch.float64) 23 353.54353880882263 89400\n",
      "tensor(0.0543, device='cuda:0') tensor(0.4953, device='cuda:0', dtype=torch.float64)\n",
      "tensor(0.0012) tensor(0.7986, device='cuda:0', dtype=torch.float64) 24 367.2934420108795 89400\n",
      "tensor(0.0419, device='cuda:0') tensor(0.5149, device='cuda:0', dtype=torch.float64)\n",
      "tensor(0.0011) tensor(0.8167, device='cuda:0', dtype=torch.float64) 25 356.18080377578735 89400\n",
      "tensor(0.0551, device='cuda:0') tensor(0.5400, device='cuda:0', dtype=torch.float64)\n",
      "tensor(0.0010) tensor(0.8325, device='cuda:0', dtype=torch.float64) 26 355.1306231021881 89400\n",
      "tensor(0.0535, device='cuda:0') tensor(0.5107, device='cuda:0', dtype=torch.float64)\n",
      "tensor(0.0009) tensor(0.8457, device='cuda:0', dtype=torch.float64) 27 354.76681685447693 89400\n",
      "tensor(0.0615, device='cuda:0') tensor(0.5109, device='cuda:0', dtype=torch.float64)\n",
      "tensor(0.0009) tensor(0.8626, device='cuda:0', dtype=torch.float64) 28 352.6526937484741 89400\n",
      "tensor(0.0617, device='cuda:0') tensor(0.5187, device='cuda:0', dtype=torch.float64)\n",
      "tensor(0.0008) tensor(0.8739, device='cuda:0', dtype=torch.float64) 29 354.0326817035675 89400\n",
      "tensor(0.0658, device='cuda:0') tensor(0.5131, device='cuda:0', dtype=torch.float64)\n",
      "tensor(0.0007) tensor(0.8882, device='cuda:0', dtype=torch.float64) 30 359.19385266304016 89400\n",
      "tensor(0.0598, device='cuda:0') tensor(0.5096, device='cuda:0', dtype=torch.float64)\n",
      "tensor(0.0007) tensor(0.8983, device='cuda:0', dtype=torch.float64) 31 359.80062103271484 89400\n",
      "tensor(0.0591, device='cuda:0') tensor(0.5044, device='cuda:0', dtype=torch.float64)\n",
      "tensor(0.0006) tensor(0.9091, device='cuda:0', dtype=torch.float64) 32 356.70066261291504 89400\n",
      "tensor(0.0647, device='cuda:0') tensor(0.5140, device='cuda:0', dtype=torch.float64)\n",
      "tensor(0.0006) tensor(0.9173, device='cuda:0', dtype=torch.float64) 33 362.30248379707336 89400\n",
      "tensor(0.0649, device='cuda:0') tensor(0.5453, device='cuda:0', dtype=torch.float64)\n",
      "tensor(0.0005) tensor(0.9282, device='cuda:0', dtype=torch.float64) 34 371.8224971294403 89400\n",
      "tensor(0.0583, device='cuda:0') tensor(0.5307, device='cuda:0', dtype=torch.float64)\n",
      "tensor(0.0005) tensor(0.9343, device='cuda:0', dtype=torch.float64) 35 357.07040214538574 89400\n",
      "tensor(0.0579, device='cuda:0') tensor(0.5267, device='cuda:0', dtype=torch.float64)\n",
      "tensor(0.0004) tensor(0.9418, device='cuda:0', dtype=torch.float64) 36 359.26745080947876 89400\n",
      "tensor(0.0743, device='cuda:0') tensor(0.5676, device='cuda:0', dtype=torch.float64)\n",
      "tensor(0.0004) tensor(0.9487, device='cuda:0', dtype=torch.float64) 37 356.4178910255432 89400\n",
      "tensor(0.0679, device='cuda:0') tensor(0.5324, device='cuda:0', dtype=torch.float64)\n",
      "tensor(0.0004) tensor(0.9534, device='cuda:0', dtype=torch.float64) 38 361.1823675632477 89400\n",
      "tensor(0.0698, device='cuda:0') tensor(0.5622, device='cuda:0', dtype=torch.float64)\n",
      "tensor(0.0003) tensor(0.9596, device='cuda:0', dtype=torch.float64) 39 359.0714452266693 89400\n",
      "tensor(0.0523, device='cuda:0') tensor(0.5360, device='cuda:0', dtype=torch.float64)\n",
      "tensor(0.0003) tensor(0.9626, device='cuda:0', dtype=torch.float64) 40 358.9586946964264 89400\n",
      "tensor(0.0339, device='cuda:0') tensor(0.5571, device='cuda:0', dtype=torch.float64)\n",
      "tensor(0.0003) tensor(0.9669, device='cuda:0', dtype=torch.float64) 41 357.9900403022766 89400\n",
      "tensor(0.0769, device='cuda:0') tensor(0.5600, device='cuda:0', dtype=torch.float64)\n",
      "tensor(0.0003) tensor(0.9699, device='cuda:0', dtype=torch.float64) 42 354.3279392719269 89400\n",
      "tensor(0.0705, device='cuda:0') tensor(0.5336, device='cuda:0', dtype=torch.float64)\n",
      "tensor(0.0003) tensor(0.9712, device='cuda:0', dtype=torch.float64) 43 357.0511565208435 89400\n",
      "tensor(0.0656, device='cuda:0') tensor(0.5636, device='cuda:0', dtype=torch.float64)\n",
      "tensor(0.0003) tensor(0.9750, device='cuda:0', dtype=torch.float64) 44 369.1801223754883 89400\n",
      "tensor(0.0599, device='cuda:0') tensor(0.5422, device='cuda:0', dtype=torch.float64)\n",
      "tensor(0.0002) tensor(0.9774, device='cuda:0', dtype=torch.float64) 45 354.662962436676 89400\n",
      "tensor(0.0704, device='cuda:0') tensor(0.5611, device='cuda:0', dtype=torch.float64)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0002) tensor(0.9796, device='cuda:0', dtype=torch.float64) 46 353.9557430744171 89400\n",
      "tensor(0.0783, device='cuda:0') tensor(0.5516, device='cuda:0', dtype=torch.float64)\n",
      "tensor(0.0002) tensor(0.9806, device='cuda:0', dtype=torch.float64) 47 354.9023349285126 89400\n",
      "tensor(0.0783, device='cuda:0') tensor(0.5631, device='cuda:0', dtype=torch.float64)\n",
      "tensor(0.0002) tensor(0.9825, device='cuda:0', dtype=torch.float64) 48 354.2429292201996 89400\n",
      "tensor(0.0797, device='cuda:0') tensor(0.5596, device='cuda:0', dtype=torch.float64)\n",
      "tensor(0.0002) tensor(0.9820, device='cuda:0', dtype=torch.float64) 49 356.5726783275604 89400\n",
      "tensor(0.0418, device='cuda:0') tensor(0.5533, device='cuda:0', dtype=torch.float64)\n",
      "tensor(0.0002) tensor(0.9828, device='cuda:0', dtype=torch.float64) 50 356.1318850517273 89400\n",
      "tensor(0.0777, device='cuda:0') tensor(0.5424, device='cuda:0', dtype=torch.float64)\n",
      "tensor(0.0002) tensor(0.9834, device='cuda:0', dtype=torch.float64) 51 357.2260277271271 89400\n",
      "tensor(0.0758, device='cuda:0') tensor(0.5580, device='cuda:0', dtype=torch.float64)\n",
      "tensor(0.0002) tensor(0.9840, device='cuda:0', dtype=torch.float64) 52 355.0823755264282 89400\n",
      "tensor(0.0810, device='cuda:0') tensor(0.5602, device='cuda:0', dtype=torch.float64)\n",
      "tensor(0.0002) tensor(0.9840, device='cuda:0', dtype=torch.float64) 53 357.4795596599579 89400\n",
      "tensor(0.0751, device='cuda:0') tensor(0.5651, device='cuda:0', dtype=torch.float64)\n",
      "tensor(0.0002) tensor(0.9849, device='cuda:0', dtype=torch.float64) 54 364.3369483947754 89400\n",
      "tensor(0.0757, device='cuda:0') tensor(0.5580, device='cuda:0', dtype=torch.float64)\n",
      "tensor(0.0002) tensor(0.9840, device='cuda:0', dtype=torch.float64) 55 358.8916528224945 89400\n",
      "tensor(0.0778, device='cuda:0') tensor(0.5604, device='cuda:0', dtype=torch.float64)\n",
      "tensor(0.0002) tensor(0.9848, device='cuda:0', dtype=torch.float64) 56 357.74010276794434 89400\n",
      "tensor(0.0837, device='cuda:0') tensor(0.5549, device='cuda:0', dtype=torch.float64)\n",
      "tensor(0.0002) tensor(0.9865, device='cuda:0', dtype=torch.float64) 57 358.5954089164734 89400\n",
      "tensor(0.0810, device='cuda:0') tensor(0.5687, device='cuda:0', dtype=torch.float64)\n",
      "tensor(0.0002) tensor(0.9868, device='cuda:0', dtype=torch.float64) 58 358.6932280063629 89400\n",
      "tensor(0.0742, device='cuda:0') tensor(0.5611, device='cuda:0', dtype=torch.float64)\n",
      "tensor(0.0002) tensor(0.9859, device='cuda:0', dtype=torch.float64) 59 357.9568495750427 89400\n",
      "tensor(0.0811, device='cuda:0') tensor(0.5604, device='cuda:0', dtype=torch.float64)\n",
      "tensor(0.0002) tensor(0.9861, device='cuda:0', dtype=torch.float64) 60 361.6313760280609 89400\n",
      "tensor(0.0883, device='cuda:0') tensor(0.5584, device='cuda:0', dtype=torch.float64)\n",
      "tensor(0.0002) tensor(0.9858, device='cuda:0', dtype=torch.float64) 61 360.2930510044098 89400\n",
      "tensor(0.0844, device='cuda:0') tensor(0.5658, device='cuda:0', dtype=torch.float64)\n",
      "tensor(0.0002) tensor(0.9865, device='cuda:0', dtype=torch.float64) 62 359.46468925476074 89400\n",
      "tensor(0.0768, device='cuda:0') tensor(0.5571, device='cuda:0', dtype=torch.float64)\n",
      "tensor(0.0002) tensor(0.9874, device='cuda:0', dtype=torch.float64) 63 360.1833231449127 89400\n",
      "tensor(0.0759, device='cuda:0') tensor(0.5720, device='cuda:0', dtype=torch.float64)\n",
      "tensor(0.0002) tensor(0.9879, device='cuda:0', dtype=torch.float64) 64 362.05085825920105 89400\n",
      "tensor(0.0825, device='cuda:0') tensor(0.5627, device='cuda:0', dtype=torch.float64)\n",
      "tensor(0.0002) tensor(0.9877, device='cuda:0', dtype=torch.float64) 65 362.47234773635864 89400\n",
      "tensor(0.0764, device='cuda:0') tensor(0.5524, device='cuda:0', dtype=torch.float64)\n",
      "tensor(0.0002) tensor(0.9865, device='cuda:0', dtype=torch.float64) 66 372.3641481399536 89400\n",
      "tensor(0.0829, device='cuda:0') tensor(0.5582, device='cuda:0', dtype=torch.float64)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-d532c1042865>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     49\u001b[0m                 \u001b[0mfile_name\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'E:/v11/Copy of training_data-{}.npy'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     50\u001b[0m                 \u001b[1;31m# full file info\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 51\u001b[1;33m                 \u001b[0mtrain_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile_name\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mallow_pickle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     52\u001b[0m                 \u001b[0mtrdt\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrdt\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     53\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\numpy\\lib\\npyio.py\u001b[0m in \u001b[0;36mload\u001b[1;34m(file, mmap_mode, allow_pickle, fix_imports, encoding)\u001b[0m\n\u001b[0;32m    450\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mformat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen_memmap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmmap_mode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    451\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 452\u001b[1;33m                 return format.read_array(fid, allow_pickle=allow_pickle,\n\u001b[0m\u001b[0;32m    453\u001b[0m                                          pickle_kwargs=pickle_kwargs)\n\u001b[0;32m    454\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\numpy\\lib\\format.py\u001b[0m in \u001b[0;36mread_array\u001b[1;34m(fp, allow_pickle, pickle_kwargs)\u001b[0m\n\u001b[0;32m    742\u001b[0m             \u001b[0mpickle_kwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    743\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 744\u001b[1;33m             \u001b[0marray\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mpickle_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    745\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mUnicodeError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    746\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mversion_info\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m>=\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "from sklearn.utils import class_weight\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "#trainingloop\n",
    "import torch.optim as optim\n",
    "\n",
    "lr = 0.001\n",
    "batchsize=200\n",
    "\n",
    "epochs=300\n",
    "\n",
    "# create your optimizer\n",
    "optimizer = optim.Adagrad(model.parameters(), lr)\n",
    "\n",
    "for p in range(epochs):\n",
    "    k1=0\n",
    "    running_corrects = 0\n",
    "    t1=0\n",
    "    t=0\n",
    "    s=time.time()\n",
    "    for l in range(4):\n",
    "        trdt=[]\n",
    "        X=[]\n",
    "        Y=[]\n",
    "        if l==0:\n",
    "        \n",
    "            trdt=np.load('E:/v11/Copy of training_data-1.npy', allow_pickle=True)\n",
    "        \n",
    "            for i in range(2,7):\n",
    "                file_name = 'E:/v11/Copy of training_data-{}.npy'.format(i)\n",
    "                # full file info\n",
    "                train_data = np.load(file_name,allow_pickle=True)\n",
    "                trdt=np.concatenate((trdt,train_data), axis=0)\n",
    "            \n",
    "            for i in range(17,62):\n",
    "                file_name = 'E:/v11/Copy of training_data-{}.npy'.format(i)\n",
    "                # full file info\n",
    "                train_data = np.load(file_name,allow_pickle=True)\n",
    "                trdt=np.concatenate((trdt,train_data), axis=0)\n",
    "        \n",
    "        elif l==1:\n",
    "        \n",
    "            trdt=np.load('E:/v11/Copy of training_data-63.npy', allow_pickle=True)\n",
    "\n",
    "            for i in range(64,111):\n",
    "                file_name = 'E:/v11/Copy of training_data-{}.npy'.format(i)\n",
    "                # full file info\n",
    "                train_data = np.load(file_name,allow_pickle=True)\n",
    "                trdt=np.concatenate((trdt,train_data), axis=0)\n",
    "                \n",
    "        elif l==2:\n",
    "        \n",
    "            trdt=np.load('E:/v12/training_data-111.npy', allow_pickle=True)\n",
    "\n",
    "            for i in range(111,150):\n",
    "                file_name = 'E:/v12/training_data-{}.npy'.format(i)\n",
    "                # full file info\n",
    "                train_data = np.load(file_name,allow_pickle=True)\n",
    "                trdt=np.concatenate((trdt,train_data), axis=0)\n",
    "        \n",
    "        elif l==3:\n",
    "        \n",
    "            trdt=np.load('E:/v12/training_data-150.npy', allow_pickle=True)\n",
    "\n",
    "            for i in range(150,189):\n",
    "                file_name = 'E:/v12/training_data-{}.npy'.format(i)\n",
    "                # full file info\n",
    "                train_data = np.load(file_name,allow_pickle=True)\n",
    "                trdt=np.concatenate((trdt,train_data), axis=0)\n",
    "        \n",
    "        np.random.shuffle(trdt)\n",
    "        X=trdt[:,0]\n",
    "        Y=trdt[:,1]\n",
    "        \n",
    "        \n",
    "        batches=len(X)/batchsize\n",
    "        yo=[]\n",
    "        val_yo=[]\n",
    "        for i in range(len(X)):\n",
    "            yo.append(np.argmax(Y[i]))\n",
    "        \n",
    "        for val_i in range(len(val_X)):\n",
    "            val_yo.append(np.argmax(val_Y[val_i]))\n",
    "        \n",
    "        y=np.array(yo)\n",
    "        val_y=np.array(val_yo)\n",
    "        \n",
    "        for j in range(int(batches)):\n",
    "            k1=k1+batchsize\n",
    "            inp=[]\n",
    "            res=[]\n",
    "\n",
    "            for k in range(batchsize):\n",
    "                inp.append(cv2.resize(X[j*batchsize+k][30:-8,:],(166,240)))\n",
    "                res.append(y[j*batchsize+k])\n",
    "\n",
    "            inp=np.array(inp).reshape(batchsize,3,166,240)\n",
    "            inptens=torch.from_numpy(inp).type(dtype)\n",
    "\n",
    "            res=np.array(res)\n",
    "            class_weights = class_weight.compute_class_weight('balanced',\n",
    "                                                 np.unique(res),res)\n",
    "                              \n",
    "            class_weights=np.array(class_weights)\n",
    "          \n",
    "            cw={}\n",
    "            k=0\n",
    "            for i in range(9):\n",
    "                if i in np.unique(res):\n",
    "                    cw[i]=class_weights[k]\n",
    "                    k=k+1\n",
    "                else:\n",
    "                    cw[i]=10000000\n",
    "            \n",
    "            c=np.array(list(cw.values()))\n",
    "            c=torch.from_numpy(c).type(dtype)\n",
    "            \n",
    "            restens=torch.from_numpy(res).type(dtype)\n",
    "\n",
    "            #forward pass\n",
    "            out=model(inptens).type(dtype)\n",
    "            #compute loss\n",
    "\n",
    "            criterion = nn.CrossEntropyLoss(weight=c)\n",
    "            loss = criterion(out,restens.long().squeeze()).type(dtype)\n",
    "\n",
    "            #backprop loss i.e. find dloss/dparam for each parameter and store.\n",
    "            loss.backward(retain_graph=False)\n",
    "            \n",
    "            #clip gradients\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "            #use optimiser to update\n",
    "            optimizer.step()\n",
    "            \n",
    "            _, preds = torch.max(out, 1)\n",
    "\n",
    "            running_corrects += torch.sum(preds == restens)\n",
    "            t=loss\n",
    "            t1=t1+t.detach().cpu()\n",
    "            \n",
    "            del inptens\n",
    "            del restens\n",
    "            del t\n",
    "            del class_weights\n",
    "            del c\n",
    "            \n",
    "            torch.cuda.empty_cache()\n",
    "            torch.cuda.reset_max_memory_allocated()\n",
    "            torch.cuda.empty_cache()\n",
    "    \n",
    "    \n",
    "    val_running_corrects=0\n",
    "    val_loss=0\n",
    "    \n",
    "    val_inp=[]\n",
    "    val_res=[]\n",
    "    \n",
    "    for val_k in range(len(val_X)):\n",
    "                val_inp.append(cv2.resize(val_X[val_k][30:-8,:],(166,240)))\n",
    "                val_res.append(val_y[val_k])   \n",
    "                \n",
    "    b=batchsize\n",
    "    for t in range(int(len(val_X)/b)):\n",
    "        val_inp1=np.array(val_inp[t*b:t*b+b]).reshape(b,3,166,240)\n",
    "        val_inptens=torch.from_numpy(val_inp1).type(dtype)\n",
    "\n",
    "        val_res1=np.array(val_res[t*b:t*b+b])\n",
    "        val_restens=torch.from_numpy(val_res1).type(dtype)\n",
    "        \n",
    "        val_class_weights = class_weight.compute_class_weight('balanced',np.unique(val_res),val_res)\n",
    "        val_class_weights=np.array(val_class_weights)\n",
    "          \n",
    "        cw={}\n",
    "        k=0\n",
    "        for i in range(9):\n",
    "            if i in np.unique(val_res1):\n",
    "                cw[i]=val_class_weights[k]\n",
    "                k=k+1\n",
    "            else:\n",
    "                cw[i]=10000000\n",
    "            \n",
    "        val_c=np.array(list(cw.values()))\n",
    "        val_c=torch.from_numpy(val_c).type(dtype)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            val_out=model(val_inptens).type(dtype)\n",
    "        _, val_preds = torch.max(val_out, 1)\n",
    "\n",
    "        val_running_corrects += torch.sum(val_preds == val_restens)\n",
    "\n",
    "        val_criterion = nn.CrossEntropyLoss(weight=val_c)\n",
    "        val_loss += criterion(val_out,val_restens.long().squeeze()).type(dtype)\n",
    "        \n",
    "        del val_inptens\n",
    "        del val_restens\n",
    "        del val_c\n",
    "        \n",
    "        torch.cuda.empty_cache()\n",
    "        torch.cuda.reset_max_memory_allocated()\n",
    "        torch.cuda.empty_cache()\n",
    "        \n",
    "    val_epoch_acc=val_running_corrects.double() /len(val_X)\n",
    "    \n",
    "    o=time.time()    \n",
    "    epoch_acc = running_corrects.double() /k1\n",
    "    print(t1/k1,epoch_acc,p,o-s,k1)\n",
    "    print(val_loss/len(val_X),val_epoch_acc)\n",
    "    \n",
    "    torch.save(model.state_dict(),'vijalexnet101balanceFINAL.pt')\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.imshow(X[j*batchsize+k])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X[j*batchsize+k].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trdt.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(val_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
