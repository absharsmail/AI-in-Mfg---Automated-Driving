{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "#imports necessary to define a neural network \n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "#ensure you are using GPU.\n",
    "if torch.cuda.is_available():  \n",
    "  dev = \"cuda:0\" \n",
    "else:  \n",
    "  dev = \"cpu\"  \n",
    "\n",
    "device = torch.device(dev)\n",
    "print(device)\n",
    "\n",
    "dtype = torch.cuda.FloatTensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in C:\\Users\\Ant Pc/.cache\\torch\\hub\\pytorch_vision_master\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AlexNet(\n",
       "  (features): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(11, 11), stride=(4, 4), padding=(2, 2))\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (3): Conv2d(64, 192, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "    (4): ReLU(inplace=True)\n",
       "    (5): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (6): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (7): ReLU(inplace=True)\n",
       "    (8): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (9): ReLU(inplace=True)\n",
       "    (10): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (11): ReLU(inplace=True)\n",
       "    (12): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(6, 6))\n",
       "  (classifier): Sequential(\n",
       "    (0): Dropout(p=0.5, inplace=False)\n",
       "    (1): Linear(in_features=9216, out_features=4096, bias=True)\n",
       "    (2): ReLU(inplace=True)\n",
       "    (3): Dropout(p=0.5, inplace=False)\n",
       "    (4): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "    (5): ReLU(inplace=True)\n",
       "    (6): Linear(in_features=4096, out_features=1000, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = torch.hub.load('pytorch/vision', 'alexnet', pretrained=False,force_reload=False)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AlexNet(\n",
       "  (features): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(11, 11), stride=(4, 4), padding=(2, 2))\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (3): Conv2d(64, 192, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "    (4): ReLU(inplace=True)\n",
       "    (5): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (6): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (7): ReLU(inplace=True)\n",
       "    (8): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (9): ReLU(inplace=True)\n",
       "    (10): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (11): ReLU(inplace=True)\n",
       "    (12): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(6, 6))\n",
       "  (classifier): Sequential(\n",
       "    (0): Dropout(p=0.5, inplace=False)\n",
       "    (1): Linear(in_features=9216, out_features=4096, bias=True)\n",
       "    (2): ReLU(inplace=True)\n",
       "    (3): Dropout(p=0.5, inplace=False)\n",
       "    (4): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "    (5): ReLU(inplace=True)\n",
       "    (6): Linear(in_features=4096, out_features=4, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import cv2\n",
    "model.classifier[6]=nn.Linear(4096,4)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "val=[]\n",
    "\n",
    "valw=np.load('C:/Users/Ant Pc/GitHub/AI-in-Mfg---Automated-Driving/w1.npy', allow_pickle=True)\n",
    "vals=np.load('C:/Users/Ant Pc/GitHub/AI-in-Mfg---Automated-Driving/s1.npy', allow_pickle=True)\n",
    "vald=np.load('C:/Users/Ant Pc/GitHub/AI-in-Mfg---Automated-Driving/d1.npy', allow_pickle=True)\n",
    "vala=np.load('C:/Users/Ant Pc/GitHub/AI-in-Mfg---Automated-Driving/a1.npy', allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i in range(400):\n",
    "    \n",
    "    val.append(np.append(valw[i,0],0))\n",
    "    val.append(np.append(vala[i,0],1))\n",
    "    val.append(np.append(vals[i,0],2))\n",
    "    val.append(np.append(vald[i,0],3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "val=np.array(val)\n",
    "np.random.shuffle(val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_X=[]\n",
    "val_Y=[]\n",
    "\n",
    "for i in range(len(val)):\n",
    "    val_X.append(val[i,:-1])\n",
    "\n",
    "    val_Y.append(val[i,-1])\n",
    "    \n",
    "val_Y=np.array(val_Y).reshape(len(val),-1)\n",
    "val_X=np.array(val_X).reshape(len(val),-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1600"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(val_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0632) tensor(0.6779, device='cuda:0', dtype=torch.float64) 0 217.83501195907593 24704\n",
      "tensor(0.0222, device='cuda:0') tensor(0.5438, device='cuda:0', dtype=torch.float64)\n",
      "tensor(0.0072) tensor(0.8200, device='cuda:0', dtype=torch.float64) 1 190.41906309127808 24704\n",
      "tensor(0.0223, device='cuda:0') tensor(0.5419, device='cuda:0', dtype=torch.float64)\n",
      "tensor(0.0056) tensor(0.8603, device='cuda:0', dtype=torch.float64) 2 188.56671738624573 24704\n",
      "tensor(0.0230, device='cuda:0') tensor(0.5431, device='cuda:0', dtype=torch.float64)\n",
      "tensor(0.0045) tensor(0.8906, device='cuda:0', dtype=torch.float64) 3 196.69471073150635 24704\n",
      "tensor(0.0238, device='cuda:0') tensor(0.6038, device='cuda:0', dtype=torch.float64)\n",
      "tensor(0.0036) tensor(0.9133, device='cuda:0', dtype=torch.float64) 4 196.70733737945557 24704\n",
      "tensor(0.0249, device='cuda:0') tensor(0.6250, device='cuda:0', dtype=torch.float64)\n",
      "tensor(0.0029) tensor(0.9317, device='cuda:0', dtype=torch.float64) 5 192.25257301330566 24704\n",
      "tensor(0.0310, device='cuda:0') tensor(0.6094, device='cuda:0', dtype=torch.float64)\n",
      "tensor(0.0024) tensor(0.9454, device='cuda:0', dtype=torch.float64) 6 195.53601002693176 24704\n",
      "tensor(0.0362, device='cuda:0') tensor(0.6300, device='cuda:0', dtype=torch.float64)\n",
      "tensor(0.0020) tensor(0.9568, device='cuda:0', dtype=torch.float64) 7 196.14003038406372 24704\n",
      "tensor(0.0341, device='cuda:0') tensor(0.6462, device='cuda:0', dtype=torch.float64)\n",
      "tensor(0.0016) tensor(0.9651, device='cuda:0', dtype=torch.float64) 8 198.4271581172943 24704\n",
      "tensor(0.0522, device='cuda:0') tensor(0.5675, device='cuda:0', dtype=torch.float64)\n",
      "tensor(0.0014) tensor(0.9718, device='cuda:0', dtype=torch.float64) 9 203.56899428367615 24704\n",
      "tensor(0.0539, device='cuda:0') tensor(0.6200, device='cuda:0', dtype=torch.float64)\n",
      "tensor(0.0012) tensor(0.9760, device='cuda:0', dtype=torch.float64) 10 192.060045003891 24704\n",
      "tensor(0.0572, device='cuda:0') tensor(0.6069, device='cuda:0', dtype=torch.float64)\n",
      "tensor(0.0011) tensor(0.9789, device='cuda:0', dtype=torch.float64) 11 188.36216115951538 24704\n",
      "tensor(0.0573, device='cuda:0') tensor(0.6125, device='cuda:0', dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "from sklearn.utils import class_weight\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "#trainingloop\n",
    "import torch.optim as optim\n",
    "\n",
    "lr = 0.001\n",
    "batchsize=64\n",
    "\n",
    "epochs=300\n",
    "\n",
    "# create your optimizer\n",
    "optimizer = optim.Adagrad(model.parameters(), lr)\n",
    "\n",
    "for p in range(epochs):\n",
    "    k1=0\n",
    "    running_corrects = 0\n",
    "    t1=0\n",
    "    t=0\n",
    "    s=time.time()\n",
    "    l=0\n",
    "    for l in range(7):\n",
    "        trdt=[]\n",
    "        X=[]\n",
    "        Y=[]\n",
    "        if l==0:\n",
    "        \n",
    "            trdt=np.load('C:/Users/Ant Pc/GitHub/AI-in-Mfg---Automated-Driving/w2.npy', allow_pickle=True)\n",
    "            t=[]\n",
    "            for i in range(len(trdt)):\n",
    "                t.append(np.append(trdt[i][0],0))\n",
    "            trdt=np.array(t)\n",
    "            lw=la=ls=ld=0\n",
    "                \n",
    "            for i in range(2,3):\n",
    "                file_name = 'C:/Users/Ant Pc/GitHub/AI-in-Mfg---Automated-Driving/d{}.npy'.format(i)\n",
    "                \n",
    "                # full file info\n",
    "                train_data = np.load(file_name,allow_pickle=True)\n",
    "                t=[]\n",
    "                for i in range(len(train_data)):\n",
    "                    t.append(np.append(train_data[i][0],3))\n",
    "                train_data=np.array(t)\n",
    "                trdt=np.concatenate((trdt,train_data), axis=0)\n",
    "                ld=len(trdt)-lw\n",
    "            #print(ld,'d')\n",
    "                \n",
    "            for i in range(2,3):\n",
    "                file_name = 'C:/Users/Ant Pc/GitHub/AI-in-Mfg---Automated-Driving/a{}.npy'.format(i)\n",
    "                # full file info\n",
    "                train_data = np.load(file_name,allow_pickle=True)\n",
    "                t=[]\n",
    "                for i in range(len(train_data)):\n",
    "                    t.append(np.append(train_data[i][0],1))\n",
    "                train_data=np.array(t)\n",
    "                trdt=np.concatenate((trdt,train_data), axis=0)\n",
    "                la=len(trdt)-ld-lw\n",
    "            #print(la,'a')\n",
    "            \n",
    "            for i in range(1,2):\n",
    "                file_name = 'C:/Users/Ant Pc/GitHub/AI-in-Mfg---Automated-Driving/s{}.npy'.format(i)\n",
    "                # full file info\n",
    "                if i==1:\n",
    "                    train_data1 = np.load(file_name,allow_pickle=True)\n",
    "                    train_data = train_data1[:,:]\n",
    "                else:\n",
    "                    train_data = np.load(file_name,allow_pickle=True)\n",
    "                t=[]\n",
    "                for i in range(len(train_data)):\n",
    "                    t.append(np.append(train_data[i][0],2))\n",
    "                train_data=np.array(t)\n",
    "                    \n",
    "                trdt=np.concatenate((trdt,train_data), axis=0)\n",
    "                ls=len(trdt)-lw-la-ld\n",
    "            #print(ls,'s')\n",
    "        \n",
    "        elif l==1:\n",
    "        \n",
    "            trdt=np.load('C:/Users/Ant Pc/GitHub/AI-in-Mfg---Automated-Driving/w3.npy', allow_pickle=True)\n",
    "            t=[]\n",
    "            for i in range(len(trdt)):\n",
    "                t.append(np.append(trdt[i][0],0))\n",
    "            trdt=np.array(t)\n",
    "        \n",
    "            for i in range(3,4):\n",
    "                file_name = 'C:/Users/Ant Pc/GitHub/AI-in-Mfg---Automated-Driving/d{}.npy'.format(i)\n",
    "                # full file info\n",
    "                train_data = np.load(file_name,allow_pickle=True)\n",
    "                t=[]\n",
    "                for i in range(len(train_data)):\n",
    "                    t.append(np.append(train_data[i][0],3))\n",
    "                train_data=np.array(t)\n",
    "                    \n",
    "                trdt=np.concatenate((trdt,train_data), axis=0)\n",
    "                ld=len(trdt)-lw\n",
    "            #print(ld,'d')\n",
    "                \n",
    "            for i in range(3,4):\n",
    "                file_name = 'C:/Users/Ant Pc/GitHub/AI-in-Mfg---Automated-Driving/a{}.npy'.format(i)\n",
    "                # full file info\n",
    "                train_data = np.load(file_name,allow_pickle=True)\n",
    "                t=[]\n",
    "                for i in range(len(train_data)):\n",
    "                    t.append(np.append(train_data[i][0],1))\n",
    "                train_data=np.array(t)\n",
    "                    \n",
    "                trdt=np.concatenate((trdt,train_data), axis=0)\n",
    "                la=len(trdt)-ld-lw\n",
    "            #print(la,'a')\n",
    "                \n",
    "            for i in range(2,3):\n",
    "                file_name = 'C:/Users/Ant Pc/GitHub/AI-in-Mfg---Automated-Driving/s{}.npy'.format(i)\n",
    "                # full file info\n",
    "                if i==1:\n",
    "                    train_data1 = np.load(file_name,allow_pickle=True)\n",
    "                    train_data = train_data1[:,:]\n",
    "                else:\n",
    "                    train_data=np.load(file_name,allow_pickle=True)\n",
    "                t=[]\n",
    "                for i in range(len(train_data)):\n",
    "                    t.append(np.append(train_data[i][0],2))\n",
    "                train_data=np.array(t)\n",
    "                    \n",
    "                trdt=np.concatenate((trdt,train_data), axis=0)\n",
    "                ls=len(trdt)-lw-la-ld\n",
    "        elif l==2:\n",
    "        \n",
    "            trdt=np.load('C:/Users/Ant Pc/GitHub/AI-in-Mfg---Automated-Driving/w4.npy', allow_pickle=True)\n",
    "            t=[]\n",
    "            for i in range(len(trdt)):\n",
    "                t.append(np.append(trdt[i][0],0))\n",
    "            trdt=np.array(t)\n",
    "        \n",
    "            for i in range(6,7):\n",
    "                file_name = 'C:/Users/Ant Pc/GitHub/AI-in-Mfg---Automated-Driving/d{}.npy'.format(i)\n",
    "                # full file info\n",
    "                train_data = np.load(file_name,allow_pickle=True)\n",
    "                t=[]\n",
    "                for i in range(len(train_data)):\n",
    "                    t.append(np.append(train_data[i][0],3))\n",
    "                train_data=np.array(t)\n",
    "                    \n",
    "                trdt=np.concatenate((trdt,train_data), axis=0)\n",
    "                ld=len(trdt)-lw\n",
    "            #print(ld,'d')\n",
    "                \n",
    "            for i in range(7,8):\n",
    "                file_name = 'C:/Users/Ant Pc/GitHub/AI-in-Mfg---Automated-Driving/a{}.npy'.format(i)\n",
    "                # full file info\n",
    "                train_data = np.load(file_name,allow_pickle=True)\n",
    "                t=[]\n",
    "                for i in range(len(train_data)):\n",
    "                    t.append(np.append(train_data[i][0],1))\n",
    "                train_data=np.array(t)\n",
    "                    \n",
    "                trdt=np.concatenate((trdt,train_data), axis=0)\n",
    "                la=len(trdt)-ld-lw\n",
    "            #print(la,'a')\n",
    "                \n",
    "            for i in range(1,2):\n",
    "                file_name = 'C:/Users/Ant Pc/GitHub/AI-in-Mfg---Automated-Driving/s{}.npy'.format(i)\n",
    "                # full file info\n",
    "                if i==1:\n",
    "                    train_data1 = np.load(file_name,allow_pickle=True)\n",
    "                    train_data = train_data1[:,:]\n",
    "                else:\n",
    "                    train_data=np.load(file_name,allow_pickle=True)\n",
    "                t=[]\n",
    "                for i in range(len(train_data)):\n",
    "                    t.append(np.append(train_data[i][0],2))\n",
    "                train_data=np.array(t)\n",
    "                    \n",
    "                trdt=np.concatenate((trdt,train_data), axis=0)\n",
    "                ls=len(trdt)-lw-la-ld\n",
    "        elif l==3:\n",
    "        \n",
    "            trdt=np.load('C:/Users/Ant Pc/GitHub/AI-in-Mfg---Automated-Driving/w4.npy', allow_pickle=True)\n",
    "            t=[]\n",
    "            for i in range(len(trdt)):\n",
    "                t.append(np.append(trdt[i][0],0))\n",
    "            trdt=np.array(t)\n",
    "                \n",
    "            for i in range(7,8):\n",
    "                file_name = 'C:/Users/Ant Pc/GitHub/AI-in-Mfg---Automated-Driving/d{}.npy'.format(i)\n",
    "                # full file info\n",
    "                train_data = np.load(file_name,allow_pickle=True)\n",
    "                t=[]\n",
    "                for i in range(len(train_data)):\n",
    "                    t.append(np.append(train_data[i][0],3))\n",
    "                train_data=np.array(t)\n",
    "                    \n",
    "                trdt=np.concatenate((trdt,train_data), axis=0)\n",
    "                ld=len(trdt)-lw\n",
    "            #print(ld,'d')\n",
    "                \n",
    "            for i in range(8,9):\n",
    "                file_name = 'C:/Users/Ant Pc/GitHub/AI-in-Mfg---Automated-Driving/a{}.npy'.format(i)\n",
    "                # full file info\n",
    "                train_data = np.load(file_name,allow_pickle=True)\n",
    "                t=[]\n",
    "                for i in range(len(train_data)):\n",
    "                    t.append(np.append(train_data[i][0],1))\n",
    "                train_data=np.array(t)\n",
    "                    \n",
    "                trdt=np.concatenate((trdt,train_data), axis=0)\n",
    "                la=len(trdt)-ld-lw\n",
    "            #print(la,'a')\n",
    "                \n",
    "            for i in range(2,3):\n",
    "                file_name = 'C:/Users/Ant Pc/GitHub/AI-in-Mfg---Automated-Driving/s{}.npy'.format(i)\n",
    "                # full file info\n",
    "                if i==1:\n",
    "                    train_data1 = np.load(file_name,allow_pickle=True)\n",
    "                    train_data = train_data1[:,:]\n",
    "                else:\n",
    "                    train_data=np.load(file_name,allow_pickle=True)\n",
    "                t=[]\n",
    "                for i in range(len(train_data)):\n",
    "                    t.append(np.append(train_data[i][0],2))\n",
    "                train_data=np.array(t)\n",
    "                    \n",
    "                trdt=np.concatenate((trdt,train_data), axis=0)\n",
    "                ls=len(trdt)-lw-la-ld\n",
    "        elif l==4:\n",
    "        \n",
    "            trdt=np.load('C:/Users/Ant Pc/GitHub/AI-in-Mfg---Automated-Driving/w5.npy', allow_pickle=True)\n",
    "            t=[]\n",
    "            for i in range(len(trdt)):\n",
    "                t.append(np.append(trdt[i][0],0))\n",
    "            trdt=np.array(t)\n",
    "                \n",
    "            for i in range(4,5):\n",
    "                file_name = 'C:/Users/Ant Pc/GitHub/AI-in-Mfg---Automated-Driving/d{}.npy'.format(i)\n",
    "                # full file info\n",
    "                train_data = np.load(file_name,allow_pickle=True)\n",
    "                t=[]\n",
    "                for i in range(len(train_data)):\n",
    "                    t.append(np.append(train_data[i][0],3))\n",
    "                train_data=np.array(t)\n",
    "                    \n",
    "                trdt=np.concatenate((trdt,train_data), axis=0)\n",
    "                ld=len(trdt)-lw\n",
    "            #print(ld,'d')\n",
    "                \n",
    "            for i in range(4,5):\n",
    "                file_name = 'C:/Users/Ant Pc/GitHub/AI-in-Mfg---Automated-Driving/a{}.npy'.format(i)\n",
    "                # full file info\n",
    "                train_data = np.load(file_name,allow_pickle=True)\n",
    "                t=[]\n",
    "                for i in range(len(train_data)):\n",
    "                    t.append(np.append(train_data[i][0],1))\n",
    "                train_data=np.array(t)\n",
    "                    \n",
    "                trdt=np.concatenate((trdt,train_data), axis=0)\n",
    "                la=len(trdt)-ld-lw\n",
    "            #print(la,'a')\n",
    "                \n",
    "            for i in range(2,3):\n",
    "                file_name = 'C:/Users/Ant Pc/GitHub/AI-in-Mfg---Automated-Driving/s{}.npy'.format(i)\n",
    "                # full file info\n",
    "                if i==1:\n",
    "                    train_data1 = np.load(file_name,allow_pickle=True)\n",
    "                    train_data = train_data1[:,:]\n",
    "                else:\n",
    "                    train_data=np.load(file_name,allow_pickle=True)\n",
    "                t=[]\n",
    "                for i in range(len(train_data)):\n",
    "                    t.append(np.append(train_data[i][0],2))\n",
    "                train_data=np.array(t)\n",
    "                    \n",
    "                trdt=np.concatenate((trdt,train_data), axis=0)\n",
    "                ls=len(trdt)-lw-la-ld\n",
    "        elif l==5:\n",
    "        \n",
    "            trdt=np.load('C:/Users/Ant Pc/GitHub/AI-in-Mfg---Automated-Driving/w6.npy', allow_pickle=True)\n",
    "            t=[]\n",
    "            for i in range(len(trdt)):\n",
    "                t.append(np.append(trdt[i][0],0))\n",
    "            trdt=np.array(t)\n",
    "                \n",
    "            for i in range(5,6):\n",
    "                file_name = 'C:/Users/Ant Pc/GitHub/AI-in-Mfg---Automated-Driving/d{}.npy'.format(i)\n",
    "                # full file info\n",
    "                train_data = np.load(file_name,allow_pickle=True)\n",
    "                t=[]\n",
    "                for i in range(len(train_data)):\n",
    "                    t.append(np.append(train_data[i][0],3))\n",
    "                train_data=np.array(t)\n",
    "                    \n",
    "                trdt=np.concatenate((trdt,train_data), axis=0)\n",
    "                ld=len(trdt)-lw\n",
    "            #print(ld,'d')\n",
    "                \n",
    "            for i in range(5,6):\n",
    "                file_name = 'C:/Users/Ant Pc/GitHub/AI-in-Mfg---Automated-Driving/a{}.npy'.format(i)\n",
    "                # full file info\n",
    "                train_data = np.load(file_name,allow_pickle=True)\n",
    "                t=[]\n",
    "                for i in range(len(train_data)):\n",
    "                    t.append(np.append(train_data[i][0],1))\n",
    "                train_data=np.array(t)\n",
    "                    \n",
    "                trdt=np.concatenate((trdt,train_data), axis=0)\n",
    "                la=len(trdt)-ld-lw\n",
    "            #print(la,'a')\n",
    "                \n",
    "            for i in range(1,2):\n",
    "                file_name = 'C:/Users/Ant Pc/GitHub/AI-in-Mfg---Automated-Driving/s{}.npy'.format(i)\n",
    "                # full file info\n",
    "                if i==1:\n",
    "                    train_data1 = np.load(file_name,allow_pickle=True)\n",
    "                    train_data = train_data1[:,:]\n",
    "                else:\n",
    "                    train_data=np.load(file_name,allow_pickle=True)\n",
    "                t=[]\n",
    "                for i in range(len(train_data)):\n",
    "                    t.append(np.append(train_data[i][0],2))\n",
    "                train_data=np.array(t)\n",
    "                    \n",
    "                trdt=np.concatenate((trdt,train_data), axis=0)\n",
    "                ls=len(trdt)-lw-la-ld\n",
    "        elif l==6:\n",
    "        \n",
    "            trdt=np.load('C:/Users/Ant Pc/GitHub/AI-in-Mfg---Automated-Driving/w4.npy', allow_pickle=True)\n",
    "            t=[]\n",
    "            for i in range(len(trdt)):\n",
    "                t.append(np.append(trdt[i][0],0))\n",
    "            trdt=np.array(t)\n",
    "                \n",
    "            for i in range(7,8):\n",
    "                file_name = 'C:/Users/Ant Pc/GitHub/AI-in-Mfg---Automated-Driving/d{}.npy'.format(i)\n",
    "                # full file info\n",
    "                train_data = np.load(file_name,allow_pickle=True)\n",
    "                t=[]\n",
    "                for i in range(len(train_data)):\n",
    "                    t.append(np.append(train_data[i][0],3))\n",
    "                train_data=np.array(t)\n",
    "                    \n",
    "                trdt=np.concatenate((trdt,train_data), axis=0)\n",
    "                ld=len(trdt)-lw\n",
    "            #print(ld,'d')\n",
    "                \n",
    "            for i in range(7,8):\n",
    "                file_name = 'C:/Users/Ant Pc/GitHub/AI-in-Mfg---Automated-Driving/a{}.npy'.format(i)\n",
    "                # full file info\n",
    "                train_data = np.load(file_name,allow_pickle=True)\n",
    "                t=[]\n",
    "                for i in range(len(train_data)):\n",
    "                    t.append(np.append(train_data[i][0],1))\n",
    "                train_data=np.array(t)\n",
    "                    \n",
    "                trdt=np.concatenate((trdt,train_data), axis=0)\n",
    "                la=len(trdt)-ld-lw\n",
    "            #print(la,'a')\n",
    "                \n",
    "            for i in range(2,3):\n",
    "                file_name = 'C:/Users/Ant Pc/GitHub/AI-in-Mfg---Automated-Driving/s{}.npy'.format(i)\n",
    "                # full file info\n",
    "                if i==1:\n",
    "                    train_data1 = np.load(file_name,allow_pickle=True)\n",
    "                    train_data = train_data1[:,:]\n",
    "                else:\n",
    "                    train_data=np.load(file_name,allow_pickle=True)\n",
    "                t=[]\n",
    "                for i in range(len(train_data)):\n",
    "                    t.append(np.append(train_data[i][0],2))\n",
    "                train_data=np.array(t)\n",
    "                    \n",
    "                trdt=np.concatenate((trdt,train_data), axis=0)\n",
    "                ls=len(trdt)-lw-la-ld\n",
    "        np.random.shuffle(trdt)\n",
    "        X=[]\n",
    "        Y=[]\n",
    "\n",
    "        for i in range(len(trdt)):\n",
    "            X.append(trdt[i,:-1])\n",
    "            Y.append(trdt[i,-1])\n",
    "        Y=np.array(Y).reshape(len(trdt),-1)\n",
    "        X=np.array(X).reshape(len(trdt),-1)\n",
    "        \n",
    "        batches=len(X)/batchsize\n",
    "        \n",
    "        y=np.array(Y)\n",
    "        val_y=np.array(val_Y)\n",
    "        \n",
    "        for j in range(int(batches)):\n",
    "            k1=k1+batchsize\n",
    "            inp=[]\n",
    "            res=[]\n",
    "\n",
    "            for k in range(batchsize):\n",
    "                inp.append(X[j*batchsize+k])\n",
    "                res.append(y[j*batchsize+k])\n",
    "\n",
    "            inp=np.array(inp).reshape(batchsize,3,270,480)\n",
    "            inptens=torch.from_numpy(inp).type(dtype)\n",
    "\n",
    "            res=np.array(res)\n",
    "            \n",
    "            restens=torch.from_numpy(res).type(dtype)\n",
    "\n",
    "            #forward pass\n",
    "            out=model(inptens).type(dtype)\n",
    "            \n",
    "            #compute loss\n",
    "\n",
    "            criterion = nn.CrossEntropyLoss()\n",
    "            #print(out.shape)\n",
    "            loss = criterion(out,restens.long().squeeze()).type(dtype)\n",
    "\n",
    "            #backprop loss i.e. find dloss/dparam for each parameter and store.\n",
    "            loss.backward(retain_graph=False)\n",
    "            \n",
    "            #clip gradients\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "            #use optimiser to update\n",
    "            optimizer.step()\n",
    "            \n",
    "            _, preds = torch.max(out, 1)\n",
    "            \n",
    "            running_corrects += torch.sum(torch.reshape(preds,[64,1]) == restens)\n",
    "           \n",
    "            t=loss\n",
    "            t1=t1+t.detach().cpu()\n",
    "            \n",
    "            del inptens\n",
    "            del restens\n",
    "            del t\n",
    "            \n",
    "            torch.cuda.empty_cache()\n",
    "            torch.cuda.reset_max_memory_allocated()\n",
    "            torch.cuda.empty_cache()\n",
    "    \n",
    "    \n",
    "    val_running_corrects=0\n",
    "    val_loss=0\n",
    "    \n",
    "    val_inp=[]\n",
    "    val_res=[]\n",
    "    \n",
    "    for val_k in range(len(val_X)):\n",
    "        val_inp.append(val_X[val_k])\n",
    "        val_res.append(val_y[val_k])   \n",
    "                \n",
    "    b=batchsize\n",
    "    for t in range(int(len(val_X)/b)):\n",
    "        val_inp1=np.array(val_inp[t*b:t*b+b]).reshape(b,3,270,480)\n",
    "        val_inptens=torch.from_numpy(val_inp1).type(dtype)\n",
    "\n",
    "        val_res1=np.array(val_res[t*b:t*b+b])\n",
    "        val_restens=torch.from_numpy(val_res1).type(dtype)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            val_out=model(val_inptens).type(dtype)\n",
    "        \n",
    "        _, val_preds = torch.max(val_out, 1)\n",
    "\n",
    "        val_running_corrects += torch.sum(torch.reshape(val_preds,[64,1]) == val_restens)\n",
    "\n",
    "        val_criterion = nn.CrossEntropyLoss()\n",
    "        val_loss += criterion(val_out,val_restens.long().squeeze()).type(dtype)\n",
    "        \n",
    "        del val_inptens\n",
    "        del val_restens\n",
    "        \n",
    "        torch.cuda.empty_cache()\n",
    "        torch.cuda.reset_max_memory_allocated()\n",
    "        torch.cuda.empty_cache()\n",
    "        \n",
    "    \n",
    "    val_epoch_acc=val_running_corrects.double() /len(val_X)\n",
    "    \n",
    "    o=time.time()    \n",
    "    epoch_acc = running_corrects.double() /k1\n",
    "    print(t1/k1,epoch_acc,p,o-s,k1)\n",
    "    print(val_loss/len(val_X),val_epoch_acc)\n",
    "    \n",
    "    torch.save(model.state_dict(),'vijalexnet101balanceFINAL.pt')\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
